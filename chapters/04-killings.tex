\chapter{What Drives State-Sponsored Violence?: Evidence from Extreme Bounds Analysis and Ensemble Learning Models}
\label{chap:killings}

\section{Introduction}
\label{sec:intro4}

Since the end of World War II, mass killings, genocides, and politicides have claimed over 34.5 million lives \citep{marshall2017pitf}.\footnote{Genocide and politicide are the attempted intentional destruction of communal or political groups, respectively \citep[see][]{harff1988toward}. Mass killing includes these atrocities, as well as attacks against civilians that result in at least 1,000 deaths but are not intended to destroy a particular group \citep[see][]{ulfelder2008assessing}. While some conflate the logic of these types of atrocities \citep[e.g.,][]{stanton2015regulating, valentino2004draining}, others claim genocide and politicide follow a different logic from other forms of government violence \citep{kalyvas2006logic,stanton2015regulating}. Note that these arguments focus on the logic of the violence, not legal definitions that separate and prioritise genocide as the crime of crimes \citep[see][]{schabas2000genocide}.} The international community has responded with an effort to prevent further state-sponsored mass murder by strengthening laws against crimes against humanity, genocide, and war crimes. It formed \textit{ad hoc}, hybrid, and a permanent criminal court to punish and deter future atrocities. Furthermore, the United Nations established a Special Adviser on the Prevention of Genocide and recognised its members’ responsibility to protect civilian populations within and outside their own borders. Yet, such atrocities still occur. Recently, President al-Assad of Syria has massacred tens of thousands of civilians during the Syrian Civil War \citep{goldman2017nyt}. Similarly, South Sudan's President Kiir is actively starving and killing civilians from dissident and rival tribes \citep{nichols2017reuters}. While there is some evidence that such atrocities may be declining since the Cold War \citep{valentino2014we}, the international community has been far from successful in realising slogans like ``Never Again'' and ``Not on My Watch'' \citep{cheadle2007not}.

Ultimately, successful prevention requires us to understand why these atrocities occur. In this vein, the academic community has laboured tremendously to establish evidence-based theories as to why governments engage in brutality against their civilian populations. Indeed, since 1995, there have been over 45 quantitative political science articles focused on explaining government-sponsored killing of civilians. Note, this number does not consider the myriad other books, qualitative articles, and non-political science research conducted into this matter. Overall, the mass violence literature generally agrees that as threat increases, so does the likelihood of atrocity, if the costs to such violence are not prohibitive. However, there is little consensus on what factors influence the level of threat or costs a regime faces. Part of the reason for this uncertainty is that scholars use very different model specifications when testing their arguments. Examining the quantitative literature on government violence against civilians, we found that in 45 studies, scholars used nearly 180 measurements to capture roughly 30 key concepts related to threat and costs. While models should be constructed specifically to test particular arguments, one concern is that small changes in model specification could in influence the robustness of empirical results and the inferences that we can draw from these results.

To overcome these limitations and provide a better understanding of government atrocity, we employ extreme bounds analysis and random forests to identify the most robust determinants of state-sponsored atrocities. Our approach is similar to \cite{hegre2006sensitivity} seminal analysis on the causes of civil war onset, but we provide additional tests to check which variables are able to predict out-of-sample cases of mass violence during both peacetime and wartime. In conducting this analysis, we address three debates in the mass violence literature:

\begin{enumerate}
    \item Why do some governments engage in mass killings, genocides, or politicides? This is the primary question asked by advocates, policymakers, and scholars in this field of research. It is also the question that the 45 studies mentioned above each attempt to answer.
    \item Does the logic underpinning government decision-making follow different patterns during peacetime and wartime. Recent research suggests that government atrocity occurs predominantly during periods of civil war \citep{harff2003no} which has led some scholars to restrict their analyses to only periods of civil war \citep[e.g.,][]{colaresi2008kill, valentino2004draining} or concentrate on predicting both the onset of civil war and atrocity \citep{goldsmith2013forecasting}. Yet, others estimate models of all country-year \citep[e.g.,][]{krain1997state, montalvo2008discrete}, raising questions of how well these studies speak to each other.
    \item Is there a difference in logic between those atrocities labelled as genocide or politicide, compared to other mass killings? While the Political Instability Task Force \citep{marshall2017pitf} provides the most widely used data on government atrocity, these data are limited only to cases of genocide and politicide. Others provide data with much more lenient inclusion criteria \citep[e.g.,][]{eck2007one, rummel1995democracy, stanton2015regulating, ulfelder2012forecasting}. These differences in definition of atrocity have led to divergent results, raising questions about important determinants of government behaviour \citep[for discussion, see][]{uzonyi2016domestic, wayman2010explaining}.
\end{enumerate}

Our analysis tests the sensitivity of 40 variables on a sample of 177 countries from 1945 to 2013. We find that GDP per capita, stable political regimes, and the post-Cold War period are negatively associated with mass killings. Conversely, previous political turmoil, ethnic diversity, and civil wars increase the risk of such violence. The distributed random forest algorithm indicates that years since the last episode of mass violence, GDP per capita, urban population, ethnic polarisation, the number of military personnel, and democracy make the greatest contribution to our models' out-of-sample predictive power. While we discuss the importance of these findings in more detail later in this article, a few notes are imperative to make here. First, in some ways, these findings confirm previous research–unstable countries are more likely to witness the regime employ atrocity \citep[e.g.,]{goldsmith2013forecasting,harff2003no,krain1997state}.  However, many of the factors scholars often cite as observable indicators of such instability--regime transitions, coups d'état, the presence of militias, etc.--are not good proxies for instability. Thus, policymakers may be looking for the incorrect signs of impending atrocity when seeking to prevent its onset. Second, these findings raise concerns about policy options for preventing violence against civilians. If our conclusion is that unstable countries are violent, then preventing atrocity likely requires significant investments of time and resources in state-building, which is often politically and practically unfeasible \citep{doyle2006making}. Lastly, our findings are robust to a myriad of specifications, functional forms, and additional tests as we describe below. This analysis contributes significantly to the political violence literature by highlighting the parsimonious nature of the logic behind government atrocity and clearing away much of the empirical clutter surrounding this conclusion. 

\section{Empirical Methods}
\label{sec:methods4}

We employ two methods to test the robustness of the potential determinants of state-led violence. First, we use a variant of extreme bounds analysis (EBA) to check the statistical significance of 35 explanatory variables cited in the academic literature.\footnote{The complete list of variables included in this article is available in appendix \ref{sec:mk-appendix}. Our selection procedure was as follows. We included all variables that appeared in at least two two quantitative papers on mass killings which employed logit or probit models in a global sample. We considered only published articles in our list.} Researchers have employed the EBA to assess the sensitivity of the determinants of civil war \citep{hegre2006sensitivity}, coups d'état \citep{gassebner2016expect}, democratisation \citep{gassebner2013extreme}, economic growth \citep{levine1992sensitivity, sala1997just, sturm2005determinants}, nuclear deterrence \citep{bell2015examining}, political repression \citep{hafner2005right}, and state corruption \citep{serra2006empirical}. The method is particularly useful when there is no consensus about which covariates belong in the ``true'' regression model \citep[178]{sala1997just} and scholars worry that omitted or unnecessary predictors could bias the parameter estimates \citep[60]{angrist2008mostly, clarke2005phantom, elwert2014endogenous, spector2011methodological}. By combining a large set of regression models into a single posterior distribution, the EBA reduces the uncertainty associated with the \textit{ad hoc} selection of predictors and provides an intuitive way of assessing the relative strength of the statistical findings \citep{leamer1985sensitivity, sala1997just}.

Second, we employ distributed random forest (DRF) \citep{breiman2001random, h2o2017} to measure the predictive power of our set of independent variables. Random forest has been widely used in the machine learning community and consistently ranks among the best algorithms for predicting structured data.\footnote{Random forests, gradient boosting machines, and neural networks have won the highest number of competitions on Kaggle, a crowd-sourced platform for predictive modelling \citep{carpenter2011may}. While data analysts prefer neural networks for problems with a high number of hidden features such as image recognition, random forest and gradient boosting are the top choices for dealing with tabular data. See: \href{https://www.kaggle.com/antgoldbloom/what-algorithms-are-most-successful-on-kaggle}{https://www.kaggle.com/antgoldbloom/what-algorithms-are-most-successful-on-kaggle} (access: December 2017).} DRF does not require distribution assumptions, can be used with any type of response variables, and are able to automatically detect nonlinear relationships between correlates \citep{fernandez2014we, hill2014empirical, jones2015exploratory, muchlinski2015comparing}. Moreover, unlike neural networks and other deep learning algorithms \citep{castelvecchi2016can,rojas2013neural,shwartz2017opening}, the output of DRF models can be interpreted meaningfully. DRF offers precise estimates of the predictive ability of each individual variable, and it also allows researchers to graphically visualise the marginal effect of the covariates on the response variable \citep{friedman2001greedy,friedman2001elements,goldstein2015peeking}.


\subsection{Extreme Bounds Analysis}
\label{subsec:eba}

The main purpose of the extreme bounds analysis is to estimate the distribution of coefficients of each predictor $x$ in an exhaustive combination of regression models with $y$ as a dependent variable. \cite[308]{leamer1985sensitivity} argued that the EBA could certify scholars that ``minor changes in the list of variables do not alter fundamentally the conclusions, nor does a slight re-weighting of observations, nor correction for dependence among observations, etcetera, etcetera.'' He proposed that ``sturdy'' variables are those whose minimum and maximum of their coefficient distribution have the same sign and are situated at a distance from zero. If we are to use the conventional value of $p < 0.05$, the mean of the variable coefficients' distribution should be located at least $1.96$ standard deviations away from zero. 

Leamer's criterion is intuitive, but other authors contend it is too strict for most social science applications. \cite{sala1997just} argued that Leamer's EBA would increase the number of false negatives; in other words, it would classify as fragile covariates that are truly associated with the response. If a given variable of interest appears as both positive and negative in the literature, it is likely that after a large a number of regressions the predictor will change signs and therefore be deemed fragile \citep[179]{sala1997just}. Sala-i-Martin then offered a less stringent version of the EBA in which researchers analyse the full distribution of point estimates instead of relying only on the coefficients' extreme bounds. 

In this paper, we follow his advice and consider the whole range of values of $CDF(0)$. We choose to use the whole distribution because the aggregate $CDF(0)$ allows us to move away from a binary indicator of robustness, the one we obtain with Leamer's extreme bounds, and present the estimations with their appropriate degrees of confidence \citep[179]{sala1997just}\footnote{As \citet[179]{sala1997just} describes, ``if 95 percent of the density function for the estimates of $\beta_{1}$ lies to the right of zero and only 52 percent of the density function for $\beta_{2}$  lies to the right of zero, one will probably think of variable 1 as being more likely to be correlated with [a dependent variable $Y$] than variable 2.''}. Our main focus is the percentage of the variable's cumulative distribution function that is smaller or greater than zero. We do not assume that the CDF has a normal distribution: Many of our coefficients do not follow a standard distribution, so the generic model provides a better fit to our data.\footnote{Histograms for all coefficients are available in appendix \ref{sec:mk-appendix}.} We specify our models as follows:

\begin{equation}
\text{\textit{Mass Killing Onset}}_{it} = \beta_{M}M_{it} + \beta_{F}F_{it} + \beta_{Z}Z_{it} + v_{it}
\end{equation}

Our main dependent variable is \textit{Mass Killing Onset}, which denotes the onset of government-sponsored killings. It was coded by \cite{ulfelder2008assessing}. The authors define a mass killing as ``any event in which the actions of state agents result in the intentional death of at least 1,000 noncombatants from a discrete group in a period of sustained violence'' \citep[2]{ulfelder2008assessing}. In our additional tests, we also estimate the models with an indicator of Genocide/Politicide Onset by \cite{harff2003no}. We prefer the first measure not only because it provides a clear numerical threshold that separates mass killings from low-level violence, but also because it focuses on the killing of members of a given community, not on the absolute number of deaths. 

The indices $i$ and $t$ indicate country and year, respectively. $M$ is a set of three covariates that are included in every model due to their prominence in the literature \citep{levine1992vale}. In our analysis, we have added the natural logarithm of the GDP per capita to control for income, the Polity IV index to control for level of democracy, and a linear time trend since the last episode of government-led atrocity to account for temporal dependence. $F$ denotes a vector of variables of interest, and $Z$ is a vector of other control variables in addition to those included in $M$. Our first model includes the variable of interest, 3 additional control variables, and 3 covariates that appear in every regression. $v$ is the error term. In practice, however, since we are interested in the effect of all variables in the data set and we do not have true control variables except from $M$, in our case $F$ and $Z$ are interchangeable. Following \citet[514]{hegre2006sensitivity}, the independent variables have been lagged one year to reduce the risk of endogeneity. Although our dependent variable is dichotomous, we use linear probability models in our main analysis. As argued by \citet[298]{gassebner2016expect}, linear probability models are less prone to convergence problems, their estimation is faster, and their results can be readily interpreted. While we do employ logistic and probit models as robustness tests, we report the coefficients of the linear probability models as our primary estimates. Moreover, since the data are grouped into countries, we use cluster-robust standard errors to control for within-cluster error correlation.
 
One of the shortcomings of our data is that some variables are strongly correlated. For instance, we include the Correlates of War's Composite Index of National Capability (\textit{CINC}), which is composed by six different variables \citep{cow2017cinc,singer1988reconstructing}.\footnote{For more information about the CINC index, please refer to the Correlates of War website: \href{http://www.correlatesofwar.org/data-sets/national-material-capabilities/national-material-capabilities-v4-0}{http://www.correlatesofwar.org/data-sets/national-material-capabilities/national-material-capabilities-v4-0} (access: December 2017).} Multicollinearity would induce bias to our estimates, so we add CINC and three of its components\footnote{The variables correspond to the ratio between the national and the global values.} -- military expenditure, military personnel, and total population -- as mutually exclusive variables. These predictors are not included in the same regression model to avoid collinearity issues.
 
We add another set of mutually exclusive variables to reduce collinearity. There are three covariates that denote ongoing civil conflicts: one measured by the Uppsala Conflict Data Program \citep{allansson2017organized,gleditsch2002armed}, another coded by the Correlates of War \citep{sarkees2010resort}, and a third indicating the onset of ethnic conflict as coded by \citet{cederman2010ethnic}. We include only one of these measures at a time. 
 
As a last precaution against collinearity, we place a limit on the Variance Inflation Factor (\textit{VIF}) of all regression coefficients. The VIF estimates how much of the variance of each predictor is dependent on the other covariates in a model. A VIF of 1 indicates that the predictor is uncorrelated with the remaining covariates. The VIF limits are often arbitrary \citep{bell2015examining,o2007caution}, thus we use a moderately conservative VIF of 7 in our estimates. As robustness tests, we run the same models with different VIF cut-offs and without restriction.

Two variables were omitted from the EBA models but included in the machine learning models below. The first is \textit{democracy}, a dummy variable that indicates whether the country is a has a Polity IV score equal or higher than 5. The second is \textit{interstate war}, a binary covariate measuring if the country is at war in a given year \citep{sarkees2010resort}. We have decided to omit democracy because of its obvious correlation with the Polity measure and interstate war due to its correlation with our dependent variables. The EBA models do not converge if those variables are added. Since this problem does not affect machine learning algorithms, the two variables were included in the second set of estimations.

Lastly, we depart slightly from Sala-i-Martin's suggested method and do not assign weights to the EBA. Although he recommends using goodness-of-fit measures to construct regression weights, we agree with \citet{sturm2002robust} and \citet[299]{gassebner2016expect} and use the unweighted version of the CDF instead. Goodness-of-fit indicators are not equivalent to the probability of a given model being true \citep{achen1977measuring,anscombe1973graphs,king1986not}, and the weights constructed this way are not invariant to transformations in the dependent variable. Moreover, our data set has a number of missing observations, so that model comparison would be misleading \citep{lall2016multiple}. Thus, the results below are for unweighted estimations. 

\subsection{Distributed Random Forest}
\label{sub:drf}

Random forest is a machine learning algorithm that consists of a combination of individual decision trees. In a classification problem, each decision tree uses a vector of covariates to split the dependent variable into two increasingly homogeneous parts \citep{breiman2001statistical}. However, decision trees are prone to overfitting, i.e., they match the original data set so closely that they tend to perform poorly with new data \citep{dietterich1995comparison,ho1998random}. Random forest, in contrast, avoids this issue by growing a decision tree only to a bootstrap sample of the original data, selecting random features at each split, then aggregating the different trees into a single prediction. If the independent variable is continuous, the algorithm will simply choose the average value of the predictions as the best candidate; if the covariate is discrete, the majority class will be employed. The simple procedure of leaving out some data points and growing separate trees with a random subset of covariates is sufficient to eliminate the risk of overfitting \citep[9-10]{jones2015exploratory}.

Random forest has many desirable properties, such as ``highly accurate predictions, robustness to noise and outliers, internally unbiased estimate of the generalisation error, efficient computation, and the ability to handle large dimensions and many predictors'' \citep[7]{muchlinski2015comparing}. Thus, random forest allows the researcher to estimate very flexible models with minimal assumptions. Unlike parametric methods such as ordinary least squares or logistic regressions, the analyst does not have to impose any distributional form to the data-generating process. As a result, random forest is able to effectively uncover complex, nonlinear interaction effects in the data without prespecification \citep{jones2015exploratory,strobl2007bias}.

The algorithm can also deal with heavily imbalanced data. Researchers can balance the classes of their response variable by assigning different sampling probability to each category. This enables the algorithm to make accurate prediction for rare events without adding prior distributions or resorting to subjective modelling choices \citep{chen2004using,del2014use,muchlinski2015comparing}.

In this paper we use distributed random forest (DRF) to model our data \citep{h2o2017}. The DRF is essentially identical to original random forest algorithm, but it has two additional features that are useful for our purposes. Firstly, DRF is optimised for big data, as it grows decision trees on separate cores to speed up computation time. Secondly, in DRF, non-observed cases are not assumed to be missing at random, but rather as values that contain information in themselves. When building decision trees, DRF treats the missing observations as a separate category that can go either left or right. This is a more conservative approach than assuming that missing cases fit into an underlying parametric distribution.\footnote{For more information about how the distributed random forest algorithm deals with missing observations, please refer to: \href{http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html}{http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html} (access: December 2017).}

The DRF has a series of hyperparameters that can be tuned to improve the algorithm's predictive performance. For instance, users can control the number of decision trees in each iteration, how deep trees should grow, which performance metric to adopt, whether to balance classes or to use cross-validation, and many other options. The interaction between parameters is generally complex and may involve thousands of potential combinations. As an example, a researcher interested in four parameters with 10 possible values each would have to estimate 10,000 models before deciding which is the most efficient one. Also, machine learning parameters are sensitive to the data at hand; so what seems an optimal solution for one problem cannot be readily implemented in another data set \citep{genuer2008random,goldstein2010application,jones2015exploratory}.

To address this issue, we have adopted an automated procedure to select the model parameters. We perform a grid search where the algorithm starts with a random combination of parameters, jumps to another randomly-chosen set, and then stops after it reaches a certain threshold \citep[123]{cook2017h2o}. We follow the literature on predictive political science and use the area under the ROC curve (AUC) as our model evaluation metric \citep[e.g.,][]{clayton2014will,hill2014empirical,ward2010perils,ward2013learning,weidmann2010predicting}. We set the metric as follows: If five random models had not increased the AUC by at least in 0.1\% comparing to the previous ones, the algorithm considers the result to be optimal. We set the maximum number of models to 1,000.

We have added several parameters to the grid search. The first is the number of independent trees to grow in each random forest model. The starting values are 256, 512, and 1024 trees. The machine learning literature does not provide a heuristic on how large a random forest should be, but \citet[166]{oshiro2012many} affirm that ``from 128 trees there is no more significant difference between the forests using 256, 512, 1024, 2048 and 4096 trees.'' We employ a more conservative approach and start from a higher value that the authors suggest as adding more trees do not reduce prediction accuracy \citep[7]{breiman2001statistical}. However, we find little evidence that the number of trees makes a noticeable difference to the estimations.

The depth of each decision tree also influences the algorithm performance. Deeper trees indicate more complex models, and in general they provide a better fit to the data. Nevertheless, this complexity comes at the risk of overfitting, so deeper trees are not necessarily the most adequate solution for every model \citep[596]{friedman2001greedy,segal2004machine}. In this article, we let the algorithm decide among using 10, 20, or 40 levels for each tree. In our view, these number offer a good balance between parsimony and complexity.

We test whether having balanced classes of our dependent variable (mass killing onset) affects the predictive ability of the model. Since the response measure is heavily imbalanced, oversampling the positive responses could potentially improve our results \citep{chawla2004special,del2014use,japkowicz2002class}. Somewhat unexpectedly, DRF had a better fit using unbalanced classes, which is the result we report in the next section.

We also vary how many variables should be considered for each split in the data. The DRF's default is to use $\sqrt{p}$, where p is the number of columns in the data set. As we have 34 covariates of interest, we have selected 5, 6 and 7 variables per split. The DRF uses a majority voting procedure to select which variable is most important. Additionally, the algorithm chooses the percentage of the training set to be modelled by each tree. The default option is 63.2\%, but we include the options of using 50\% and 100\% of the data. Similarly, we give a range of options for choosing how many columns will be included in each tree. The algorithm can randomly choose among 50\%, 90\% or 100\% of the independent variables when estimating a decision tree.

Finally, we use four types of histogram to find optimal split points for each independent variable. Decision trees consider every value of a given independent variable as a potential candidate for a split in the training data. This process is notably time-consuming, and computation time can be significantly reduced at little loss of precision by taking discrete values of the predictor distribution. The DRF algorithm offers four choices of histogram selection and we include all of them in our estimations.

\section{Results}
\label{sec:results4}

Table \ref{tab:eba1} summarises our main EBA results with Ulfelder and Valentino's \citeyear{ulfelder2008assessing} \textit{Mass Killing Onset} as the dependent variable. The table shows the average coefficient estimate of all regressions for each robust variable along with their mean standard deviations.\footnote{A list of all independent variables and coding rules are available in the online appendix.} The table also displays the percentage of regressions that are statistically significant at the 90\% level. $CDF(0)$ represents the cumulative distribution function, which is the area of the distribution that falls above or below zero.\footnote{We show whichever area is the largest. The sign of the average $\beta$ coefficient indicates if most of the cumulative distribution is located above or below zero.} This is our main statistic of interest, and we consider a covariate to be robust if it has a $CDF(0)$ of 0.9 or higher \citep[181]{sala1997just}. Lastly, we report the number of estimated regressions models which included each variable.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.0091 & 0.0052 & 76.055 & 0.9335 & 226707 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.0133 & 0.0085 & 72.845 & 0.9472 & 35614 \\
UCDP civil war onset & 0.0529 & 0.0321 & 52.378 & 0.9441 & 20854 \\
Previous riots & 0.0140 & 0.0100 & 56.242 & 0.9216 & 35614 \\
UCDP ongoing civil war & 0.0172 & 0.0115 & 65.652 & 0.9092 & 20854 \\
Ethnic diversity (ELF) & 0.0184 & 0.0137 & 56.674 & 0.9050 & 35614 \\
Polity IV squared & -0.0002 & 0.0001 & 61.206 & 0.9031 & 35614 \\ \hline
\end{tabular}
\caption{Extreme Bounds Analysis -- Mass Killings (Robust Variables Only)}
\label{tab:eba1}
\end{table}

Seven variables pass our EBA criteria. Three variables decrease the likelihood of mass killings. First, as widely suggested in the literature, the natural logarithm of GDP per capita is robustly associated with the onset of mass killings 
\citep[e.g.,][]{besanccon2005relative, easterly2006development,esteban2015strategic}. In our models, GDP per capita has a negative effect on onset risk is statistically significant in 76\% of the models. Second, the post-Cold War years are correlated with lower levels of government violence. Despite eventual outbreaks of large-scale attacks against civilians \citep[e.g.,][]{prunier2005darfur,tatum2010genocide,waldorf2009revisiting}, after 1991 these events have become less prevalent. Indeed, this finding is in line with several studies that point to a general decline in violence over the last decades, including riots, civil wars, and urban crime \citep{eisner2003long,pinker2011better}. The third variable negatively correlated with mass killings is the squared term of the Polity IV political regime index. Although the linear Polity IV indicator does not reach our threshold for significance, about 90\% of the distribution area of Polity IV squared is located below zero. This finding points to a nonlinear relationship between political regime and mass killings, thus providing further evidence that democracy reduces state-sponsored violence \citep{rost2013will,rummel1995democracy} and that regimes that mix democratic with autocratic features have the highest risk of conflict \citep{hegre2001toward,mitchell2013domestic,muchlinski2014grievances,regan2010changing}.

Four variables are positively associated with Ulfelder and Valentino's (\citeyear{ulfelder2008assessing}) indicator of state-sponsored violence. The onset and continuation of civil wars are correlated with mass killings, but only when we employ the UCDP measures of violent conflict. We find no effect for the variables compiled by the Correlates of War project or \cite{cederman2010ethnic}. Coding choices likely account for this difference, and the result is robust to a myriad of specifications. Former instances of political turmoil also have a positive coefficient in our models. Countries with a previous history of riots are more prone to state violence, which suggests that government repression is path dependent 
\citep[e.g.,][]{gurr2000peoples,harff2003no,krain1997state,nyseth2017re}. Our results also show that a higher levels of ethnic diversity increase the likelihood of atrocities against civilians. Nevertheless, the variable does not pass all additional tests we implement below and the sturdiness of this finding remains open to question. The uncertainty about the impact of ELF on mass killings is also reflected in the literature. As \citet[237]{hoeffler2016development} points out, \citet{rummel1995democracy} reports that ELF is not statistically significant in his models, \citet{wood2014opportunities} finds a negative relationship and \citet{querido2009state} finds a positive one. Our analysis does not offer a definitive answer for this question either.

A different set of variables reach significance if we only consider mass killings that occur during civil wars. We ran the models on three indicators of violent armed conflict. The first is the civil war measure by the Uppsala Conflict Database Program  (\citeyear{allansson2017organized,gleditsch2002armed}). Here, two variables meet our criteria for robustness, Post-Cold War years and conflicts with territorial aims, both negatively correlated with mass killing onset. When we limit our analysis to cases marked as civil wars by the Correlates of War project \citep{sarkees2010resort}, years since the last mass killing episode, previous riots, former human rights abuses, and ethnic diversity appear have a positive effect on the outcome. Rather surprisingly, the presence of militias has a negative effect on genocides and politicides. Finally, our model using ethnic civil war \citep{cederman2010ethnic} shows similar results: Militias have a negative impact on the likelihood of mass killings during ethnic conflict, as do conflicts over territorial aims. This finding is in contradiction with previous research \citep{koren2017means} and is deserving of further exploration. Overall, these results suggest two takeaways. First, the determinants of mass killing onset during peacetime and wartime are different from each other. While there are more restraints on atrocities during peacetime, these restraints fail once fighting begins. This raises particularly interesting questions about the pacifying nature of democracy. Second, how civil wars are classified significantly alters the results produced. This raises concerns for scholars about making claims based on only one data set.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{UCDP data} &  &  &  &  &  \\
Territory aims & -0.044 & 0.019 & 74.997 & 0.9804 & 17902 \\
Post-Cold War years & -0.038 & 0.019 & 66.574 & 0.9222 & 17902 \\
 &  &  &  &  &  \\
\textit{COW data} &  &  &  &  &  \\
Physical integrity & 0.024 & 0.013 & 66.674 & 0.9564 & 17902 \\
Militias & -0.099 & 0.048 & 73.104 & 0.9490 & 17902 \\
Years since last mass killing & 0.006 & 0.002 & 88.208 & 0.9472 & 101583 \\
Previous riots & 0.078 & 0.041 & 65.412 & 0.9348 & 17902 \\
Ethnic diversity (ELF) & 0.095 & 0.062 & 48.615 & 0.9000 & 17902 \\
 &  &  &  &  &  \\
\textit{Cederman et al. data} &  &  &  &  &  \\
Territory aims & -0.051 & 0.026 & 74.288 & 0.9167 & 17902 \\
Militias & -0.050 & 0.035 & 52.240 & 0.9101 & 17902 \\ \hline
\end{tabular}
\caption{EBA -- Mass Killings during Civil Wars (Robust Variables Only)}
\label{tab:ucdp}
\end{table}

The random forest models confirm some of the main findings of the EBA, yet they also show some interesting prediction patterns. Figure \ref{fig:drfuv} presents the six most important predictors of state-sponsored violence in out-of-sample tests. Overall, the machine learning estimations have a good fit, with an AUC of about 0.8 in the test samples.

However, the findings should be interpreted with caution since variable importance metrics are sensitive to the choice of random seed numbers. But despite that expected variation, the results in the random forest models are quite stable even when estimated with different random seeds. 

\begin{figure}[h]
\includegraphics[width=.9\textwidth, height=8cm]{images/drf.pdf}
\caption{Distributed Random Forest -- Variable Importance (Scaled)}
\label{fig:drfuv}
\end{figure}

We see that the most important predictor in our models is the natural log of GDP per capita. This confirms the findings of the EBA model. Years since the last mass killing episode has a nonlinear relationship with large-scale violence: The likelihood of renewed genocides is small in the first years, although it increases slightly over the next decades. The percentage of urban population exhibits a similar pattern. Rural areas are less prone to mass killings, yet the probability of such events rise according to a country’s level of urbanisation. We understand both GDP per capita and percentage of urban population as proxies for state capacity. Conducting a mass killing campaign demands some minimal level of military hierarchy and resources, and countries that are overwhelmingly rural are probably less able to amass the human and physical capital required to conduct such task. Furthermore, urban population tend to be less dispersed, what facilitates a large attack by government forces. 

\vspace{.5cm}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth, height=9cm]{images/drfdpp.pdf}
\caption{Distributed Random Forest -- Partial Dependence Plots}
\label{fig:drfdpp}
\end{center}
\end{figure}

The ethnic polarisation variable indicates that countries in which a large share of the population is excluded from politically relevant positions, the lower the probability of a mass killing. Groups that manage to control the state apparatus rarely face dangerous opposition movements, and as such they rarely resort to mass violence to impose their rule over the population. Next, the size of the military personnel substantially increases the likelihood of state-sponsored violence. While small and weak states tend to be more prone to civil war and other types of conflict \citep{collier2004greed,fearon2003ethnicity}, they are less likely to experience one-sided state violence. Lastly, the Polity IV index shows that mixed regimes have a higher likelihood of atrocity, and democracies tend to have lower levels of state-led violence.

With respect to mass atrocities that occur during armed conflicts, we see that log GDP per capita and years since mass killings are again relevant predictors. Additionally, both covariates are among the 10 most important predictors in the three models. The results obtained with the UCDP civil war data are broadly similar to those of the previous model, but it highlights that total battle deaths is the predictor that has a noticeable impact on mass killings onset. The partial dependence graph shows a large positive effect along the curve, with a pronounced jump at around 200,000 deaths. 

\vspace{1cm}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth, height=9cm]{images/drfdpp2.pdf}
\caption{Partial Dependence Plots -- Mass Killings during Civil Wars (UCDP data)}
\label{fig:drfdpp2}
\end{center}
\end{figure}


\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth, height=9cm]{images/drfdpp3.pdf}
\caption{Partial Dependence Plots -- Mass Killings during Civil Wars (COW data)}
\label{fig:drfdpp3}
\end{center}
\end{figure}


\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth, height=9cm]{images/drfdpp4.pdf}
\caption{Partial Dependence Plots -- Mass Killings during Civil Wars (Cederman et al. data)}
\label{fig:drfdpp4}
\end{center}
\end{figure}

\newpage

When using the COW data, we find that GDP per capita and total battle deaths have little influence in the likelihood of mass killings, and years since the last state-led atrocity increases the chances of a future event, a result we have also seen in the EBA models. As expected, higher levels of abuse against the physical integrity of citizens are associated with mass killings. Ethnic polarisation and the threshold of excluded population have a somewhat constant effect in our estimations, yet both show a sharp decline in probability when they reach their maximum levels. This provides more evidence to the idea that when certain groups are able to concentrate power, they tend not to resort to mass-scale violence as a political means.

Our last model concerns the onset of ethnic conflicts as defined by \citet{cederman2010ethnic}. The graphs show ethnic wars operate with a different dynamics than other armed conflicts. We see that an increase in all the most important predictors have a large negative impact on the likelihood of mass killings, thus we conclude that poor, unstable countries are more prone mass killings during ethnic conflicts.

\section{Additional Tests}
\label{sec:additional-tests4}

We estimate a set of additional regressions to assess the robustness of our main findings. In regard to the EBA, we include 10 variants of our original model. All of them largely confirm our prior results. First, we varied the number of covariates included in each regression to 3 and 5 while keeping the $M$ set of 3 variables included in every model, that is, the natural logarithm of GDP per capita, the Polity IV index, and a linear time trend since the last episode of state-sponsored violence. The results are identical to the main model when we add 3 control variables at a time. The same covariates discussed above remain significant and with the same sign: log of GDP per capita (negative), post-Cold War period (negative), previous riots (positive), civil war onset and ongoing indicators as measured by the UCDP data set (both positive), Polity IV squared (negative), and ethnic diversity (negative). When 5 control variables are added to every model, three variables have a CDF(0) of 0.9 or higher. They are the natural logarithm of GDP per capita, civil war onset (UCDP), previous riots, and the dummy indicating the post-Cold War period. Ethnic fractionalisation and Polity IV squared become marginally significant with a CDF(0) of about 0.88.

Second, we place different restrictions on the variance inflation factor (VIF) to test whether multicollinearity is driving our results. The test is similar to that employed by Bell (2015). While in the main analysis we use a VIF of 7, in the additional analyses we include a conservative VIF of 2.5, a less strict value of 10, and a model without any restriction. The results are unchanged. The two models with different values of VIF show identical results to the results displayed in table \ref{tab:eba1}. In the model with no VIF restriction, however, ethnic fractionalisation fails to meet our threshold by a very small margin. The CDF(0) of that covariate is 0.897, very close to the required value of 0.9.

We also estimate our models using logit and probit regressions. In order to deal with the issue of complete separation \citep{bell2015questioning,zorn2005solution} we follow \citet{gelman2008weakly} and add a weakly informative prior distribution to the coefficients. We first scaled the non-binary variables to have a mean of 0 and a standard deviation of 0.5, then we added a Cauchy distribution with center 0 and scale 2.5. The probit regressions use a scale of $2.5 \times 1.6$, which is also recommended by the authors \citep{arm2017rpackage}.

In both cases, the logarithm of GDP per capita, post-Cold War period, previous riots, and Polity IV squared remain significant. In contrast, ethnic fractionalisation and former conflict as measured by the UCDP data set are again close to the 0.9 significance level. 

In regard to random forests, grid searches are themselves a data-driven selection of many possible machine learning models, thus it is not strictly necessary to run a batch of additional tests. Nevertheless, we performed a series of grid searches using three different seeds obtained from \texttt{Random.Org} to estimate how the choice of different starting numbers would influence the model outcomes. The output of those models are largely comparable.

As a last set of robustness models, we estimate the same regressions using Harff's (\citeyear{harff2003no}) indicator of genocide and politicide. No variable appear as significant in our EBA models for genocide or politicide onset in peacetime. When we limit our sample to civil war years, the Post-Cold War period is again negatively correlated with the outcome when using the Correlates of War data set. Additionally, excluded population has a negative sign in more than 90\% of the models using both Correlates of War’s and Cederman et al's (\citeyear{cederman2010ethnic}) indicators of conflict. Displaced population also has a negative effect in the Correlates of War data set. During ethnic conflicts, our dummy variable for political assassinations has a negative impact on the onset of genocides. Overall, we conclude then that the significant covariate of genocide and politicide onset differ significantly from those of more general forms of government mass violence. Finally, the machine learning models are comparable to the ones we present above, with a similar set of variables appearing in the random forest estimations. The results are available in appendix \ref{sec:mk-appendix}.

\section{Conclusion}
\label{sec:conclusion4}

In this paper, we apply extreme bounds analysis and distributed random forests to estimate the robustness and predictive ability of 40 variables that have been pointed out as potential determinants of mass killings. We find that from all variables we employ, GDP per capita is the covariate that appears statistically significant more often in our models. In the EBA estimations, we see that the level of democracy, and the post-Cold War period are negatively associated with our dependent variable, whereas ethnic diversity, civil wars, and previous political turmoils increase the likelihood of those events. When we run a machine learning algorithm to estimate out-of-sample predictive performance, GDP per capita and years since last mass killings again appear as important predictors, and variables related to military capabilities and the composition of the population are included in most models. In a nutshell, our tests provide strong evidence in favour of two well-established findings in the specialised literature: Mass killings are unlikely to happen in rich, stable countries and there is a positive association between several types of political conflict, such as previous riots, civil wars and government atrocities.

Nevertheless, there is considerable heterogeneity in some of our findings. Mass killings are rare outcomes, so it is possible that our analysis does not capture all variables that explain the onset of large-scale violence, or that the effect of predictors vary across time and space \citep[8]{bell2015examining}. Additionally, the findings point out that mass killings may have different causes according to the context in which they erupt, so a general theory of state atrocities may obscure important details in our understanding of the root causes of state killings. 

Yet we see this diversity of outcomes under a positive light. The findings presented in this text suggest new avenues for research, and we believe they also highlight the importance of scholars moving from purely correlational, cross-country regressions to other methods that can yield more robust predictions and causal explanations. For instance, why are mass killings in ethnic conflicts correlated with a different set of variables than in armed conflicts in general? Would the results remain robust had scholars decided to code ethnic conflicts in another way? More theoretical advancement would also be welcome. Given that GDP per capita is negatively correlated to state atrocities in virtually every model, it would be interesting to unpack the causal mechanisms by which it operates by testing more specific mechanisms. Disaggregated data can also be of great help to further current research on genocides, politicide, and mass killings.

In terms of practical implications, the results indicate that regime change and pro-growth economic policies are the most efficient ways to prevent mass killings. The international community can therefore play a role in deterring leaders from using force against their own population, either by offering support for domestic opposition groups, intervening, or by fostering economic development. Although costly in the short run, these measures would substantially decrease the likelihood of state violence by breaking the ``conflict trap'' in which past conflicts create the condition for new ones \citep{collier2003breaking}. 

\newpage

\section{Appendix} 
\label{sec:mk-appendix}

This appendix contains all required information to replicate the numerical analyses presented in sections \ref{sec:results4} and \ref{sec:additional-tests4}. \textt{R} code can be found in subsection \ref{sec:mk-code} and the data are available on the following GitHub repository: \href{https://github.com/danilofreire/mass-killings}{https://github.com/danilofreire/mass-killings}. We used \texttt{R} version 3.4.4 (15-03-2018) and Ubuntu 16.04.4 LTS to perform all statistical calculations.

\subsection{Variable Selection}
\label{sec:mk-vs}

We employ some criteria to select our explanatory variables. First, we included only published articles in our sample. Although working papers and policy may also provide important insights about the onset of mass killings, we believe that peer-reviewed research is probably better suited for our purposes. Also, we included only papers that use regression methods on a global sample and were published from 1995 to 2015. Our final sample comprises 45 articles: \citet{anderton2015new}, \citet{balcells2010rivalry, balcells2011continuation}, \citet{besanccon2005relative}, \citet{bulutgil2015social}, \citet{bundervoet2009livestock}, \citet{clayton2016civilianizing}, \citet{colaresi2008kill}, \citet{downes2006desperate, downes2007restraint},  \citet{easterly2006development}, \citet{eck2007one}, \citet{esteban2015strategic}, \citet{fazal2015particular}, \citet{fjelde2014weakening}, \citet{goldsmith2013forecasting}, \citet{harff2003no}, \citet{joshi2017kills}, \citet{kim2010makes}, \citet{kim2016revolutionary}, \citet{kisangani2007political}, \citet{koren2017means}, \citet{krain1997state}, \citet{manekin2013violence}, \citet{mcdoom2013killed,mcdoom2014predicting}, \citet{melander2009new}, \citet{montalvo2008discrete}, \citet{pilster2016differentiation}, \citet{querido2009state}, \citet{raleigh2012violence}, \citet{rost2013will}, \citet{rummel1995democracy}, \citet{schneider2013accounting}, \citet{siroky2015empire}, \citet{stanton2015regulating}, \citet{sullivan2012blood}, \citet{tir2008domestic}, \citet{ulfelder2008assessing}, \citet{ulfelder2012forecasting}, \citet{uzonyi2015civil, uzonyi2016domestic} \citet{valentino2004draining}, \citet{valentino2006covenants}, \citet{verpoorten2012leave}, \citet{wayman2010explaining}, \citet{wig2016local}, and \citet{yanagizawa2014propaganda}.

We find that in those 45 studies scholars made use of nearly 180 measurements to capture roughly 30 key concepts related to threat and costs of mass killings. To be added to our models, a variable should appear in at least two articles. The covariates are summarised in table \ref{tab:mk-vs}. A complete list of variables is available at \href{https://github.com/danilofreire/mass-killings}{https://github.com/danilofreire/mass-killings}.


\begin{table}[!htbp] \centering 
  \caption{Independent Variables} 
  \label{tab:mk-vs} 
\footnotesize
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] {Variable} & \multicolumn{1}{c}{Coded} & \multicolumn{1}{c}{Source}\\ 
\hline \\[-1.8ex] 
Assassination & Dichotomous & \citet{banks1999cross} \\ 
CINC & Continuous & \citet{cow2017cinc}\\ 
Coup d'état & Dichotomous & \citet{marshall2017pitf}  \\ 
COW civil war onset & Dichotomous & \citet{cow2017cinc,singer1988reconstructing} \\ 
COW civil war ongoing & Dichotomous & \citet{cow2017cinc,singer1988reconstructing} \\ 
Democracy (Polity IV $\geq 6$) & Dichotomous  & Authors' own calculations \\ 
Discriminated dummy & Dichotomous & \citet{cederman2010ethnic}\\ 
Discriminated population & Continuous & \citet{cederman2010ethnic} \\ 
Ethnic diversity (ELF) & Continuous & \citet{fearon2003ethnicity} \\ 
Ethnic war start & Dichotomous & \citet{cederman2010ethnic} \\ 
Ethnic war ongoing & Dichotomous & \citet{cederman2010ethnic} \\ 
Excluded population & Continuous & \citet{cederman2010ethnic} \\ 
Interstate war & Dichotomous & \citet{singer1988reconstructing,cow2017cinc} \\ 
Guerrilla & Dichotomous & \citet{balcells2014does}\\ 
Military expenditure & Continuous & \citet{cow2017cinc} \\ 
Military personnel & Continuous & \citet{cow2017cinc} \\ 
Militias & Dichotomous & \citet{carey2013states} \\ 
Mountainous Terrain & Continuous & \citet{fearon2003ethnicity} \\ 
Physical integrity & Continuous & \citet{cingranelli2010cingranelli}\\ 
Polarisation (all groups/main group) & Continuous &  Authors' own calculations \\ 
Polarisation (all groups/population) & Continuous &  Authors' own calculations  \\ 
Polarisation (included groups/population) & Continuous &  Authors' own calculations  \\ 
Polarisation (included groups/main group) & Continuous &  Authors' own calculations  \\ 
Polity IV & Continuous & \citet{marshall2017pitf}\\ 
Polity IV squared & Continuous & Authors' own calculations \\ 
Population & Continuous & \citet{gleditsch2002expanded} \\
Post-Cold War & Dichotomous & Authors' own calculations \\ 
Real GDP & Continuous & \citet{gleditsch2002expanded} \\ 
Real GDP per capita & Continuous & \citet{gleditsch2002expanded} \\ 
Real GDP per capita (log) & Continuous & Authors' own calculations  \\ 
Regime transition & Continuous & Authors' own calculations \\ 
Riot & Dichotomous & \citet{banks1999cross}\\ 
Total battle deaths & Continuous & \citet{lacina2005monitoring} \\  
Total trade & Continuous & \citet{cow2017cinc} \\ 
Trade dependence (total trade/real GDP) & Continuous & Authors' own calculations \\ 
UCDP civil war onset & Dichotomous & \citet{allansson2017organized,gleditsch2002armed} \\ 
UCDP civil war ongoing & Dichotomous & \citet{allansson2017organized,gleditsch2002armed} \\ 
Urban population (percentage) & Continuous & \citet{cow2017cinc} \\ 
Years since last mass killing & Continuous & Authors' own calculations \\ 
War with territory aims & Dichotomous & \citet{allansson2017organized,gleditsch2002armed} \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 

\newpage

\subsection{Descriptive Statistics}
\label{sec:mk-ds}

\begin{table}[!htbp] \centering 
  \caption{Descriptive Statistics} 
  \label{tab:mk-ds} 
\footnotesize 
\begin{tabular}{@{\extracolsep{5pt}}lccccc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
Statistic & \multicolumn{1}{c}{N} & \multicolumn{1}{c}{Mean} & \multicolumn{1}{c}{St. Dev.} & \multicolumn{1}{c}{Min} & \multicolumn{1}{c}{Max} \\ 
\hline \\[-1.8ex] 
Country code & 9,162 & 452.84 & 247.74 & 2 & 950 \\ 
Year & 9,162 & 1,983.56 & 18.77 & 1,945 & 2,013 \\ 
Genocide/politicide onset & 8,933 & 0.005 & 0.07 & 0 & 1\\ 
Mass killing onset & 9,162 & 0.01 & 0.11 & 0 & 1 \\ 
&&&&&\\
\textit{Independent Variables} & & & & \\
&&&&&\\
Assassination dummy & 8,991 & 0.08 & 0.27 & 0 & 1 \\ 
CINC & 8,767 & 0.01 & 0.02 & 0.00 & 0.38 \\ 
Coup dummy & 8,587 & 0.05 & 0.21 & 0 & 1 \\ 
COW civil war onset & 8,160 & 0.01 & 0.12 & 0 & 1 \\ 
COW civil war ongoing & 8,160 & 0.07 & 0.25 & 0 & 1 \\ 
Democracy dummy & 8,991 & 0.37 & 0.48 & 0 & 1 \\ 
Discriminated dummy & 6,981 & 0.35 & 0.48 & 0 & 1 \\ 
Discriminated population & 6,981 & 0.06 & 0.15 & 0.00 & 0.98 \\ 
Ethnic diversity (ELF) & 6,981 & 0.41 & 0.31 & 0 & 1 \\ 
Ethnic war start & 7,760 & 0.01 & 0.12 & 0 & 1 \\ 
Ethnic war ongoing & 7,760 & 0.11 & 0.31 & 0 & 1 \\ 
Excluded population & 6,981 & 0.16 & 0.22 & 0.00 & 0.98 \\ 
Interstate war & 8,159 & 0.04 & 0.19 & 0 & 1 \\ 
Guerrilla dummy & 714 & 0.81 & 0.40 & 0 & 1 \\ 
Military expenditure & 8,290 & 4,607,120 & 27,785,906 & 0 & 693,600,000 \\ 
Military personnel & 8,620 & 176.70 & 520.90 & 0 & 12,500 \\ 
Militias & 4,097 & 0.22 & 0.42 & 0 & 1 \\ 
Mountainous Terrain & 7,358 & 2.14 & 1.43 & 0.00 & 4.56 \\ 
Physical integrity & 4,499 & 4.73 & 2.31 & 0 & 8 \\ 
Polarisation (all groups/main group) & 6,981 & 0.70 & 0.26 & 0.05 & 1 \\ 
Polarisation (all groups/population) & 6,981 & 0.63 & 0.32 & 0 & 1 \\ 
Polarisation (included groups/population) & 5,610 & 0.64 & 0.32 & 0 & 1 \\ 
Polarisation (included groups/main group) & 6,981 & 0.23 & 0.35 & 0 & 1 \\ 
Polity IV & 8,558 & 0.42 & 7.50 & $-$10 & 10 \\ 
Polity IV squared & 8,558 & 56.35 & 32.59 & 0 & 100 \\ 
Population & 8,293 & 32,993.61 & 112,886.40 & 118.21 & 1,324,353.00 \\
Post-Cold War & 8,991 & 0.40 & 0.49 & 0 & 1 \\ 
Real GDP & 8,293 & 215,317.70 & 804,827.20 & 129.68 & 13,193,478.00 \\ 
Real GDP per capita & 8,293 & 8,104.20 & 18,376.73 & 132.82 & 632,239.50 \\ 
Real GDP per capita (log) & 8,293 & 8.25 & 1.20 & 4.89 & 13.36 \\ 
Regime transition & 1,221 & $-$4.24 & 41.50 & $-$77 & 99 \\ 
Riot dummy & 8,991 & 0.16 & 0.36 & 0 & 1 \\ 
Total battle deaths & 714 & 6,050.86 & 24,404.78 & 100 & 350,000 \\  
Total trade & 8,174 & 53,804.01 & 222,209.90 & 0.80 & 4,825,363.00 \\ 
Trade dependence & 7,670 & 0.26 & 0.69 & 0.0001 & 22.11 \\ 
UCDP civil war onset & 8,733 & 0.02 & 0.14 & 0 & 1 \\ 
UCDP civil war ongoing & 8,733 & 0.15 & 0.36 & 0 & 1 \\ 
Urban population (percentage) & 8,767 & 0.22 & 0.17 & 0.00 & 1.51 \\ 
Years since last mass killing & 9,162 & 23.81 & 17.71 & 0 & 68 \\ 
War with territory aims & 8,924 & 0.07 & 0.26 & 0 & 1 \\ 
\hline \\[-1.8ex] 
\end{tabular} 
\raggedright{\newline \textit{Note}: All independent variables were lagged one year.}
\end{table} 
\normalsize

\newpage

\subsection{Extreme Bounds Analysis Extensions}
\label{sec:mk-ebae}

\subsubsection{Main Model}

We present a series of histograms with the coefficients' distribution of all variables in the main EBA model. There are 36 variables in total, seven of which are robust: Log GDP per capita, post-Cold War period, onset and ongoing civil wars (measured by the UCDP), previous riots, ethnic diversity and the squared term of the Polity IV index.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.0091 & 0.0052 & 76.055 & 0.9335 & 226707 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.0133 & 0.0085 & 72.845 & 0.9472 & 35614 \\
UCDP civil war onset & 0.0529 & 0.0321 & 52.378 & 0.9441 & 20854 \\
Previous riots & 0.0140 & 0.0100 & 56.242 & 0.9216 & 35614 \\
UCDP ongoing civil war & 0.0172 & 0.0115 & 65.652 & 0.9092 & 20854 \\
Ethnic diversity (ELF) & 0.0184 & 0.0137 & 56.674 & 0.9050 & 35614 \\
Polity IV squared & -0.0002 & 0.0001 & 61.206 & 0.9031 & 35614 \\ \hline
\end{tabular}
\caption{Extreme Bounds Analysis -- Mass killings}
\label{tab:mk}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk.pdf}
    \caption{Extreme Bounds Analysis -- Mass Killings}
    \label{fig:mk}
\end{sidewaysfigure}
\clearpage

\subsubsection{Genocides during Civil Wars}
\label{sec:civil-wars}

Next, we discuss genocides that occur during wartime. We use three covariates that denote ongoing civil conflicts: one by the Uppsala Conflict Data Program \citep{allansson2017organized,gleditsch2002armed}, another by the Correlates of War \citep{sarkees2010resort}, and a third indicating the onset of ethnic conflict as coded by \citet{cederman2010ethnic}. The variables that reach significance in this set of models below are notably different from those obtained in the main estimation. This result provides evidence that mass violence during wartime time follows a separate logic from state killings in peacetime.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{UCDP data} &  &  &  &  &  \\
Territory aims & -0.044 & 0.019 & 74.997 & 0.9804 & 17902 \\
Post-Cold War years & -0.038 & 0.019 & 66.574 & 0.9222 & 17902 \\
 &  &  &  &  &  \\
\textit{COW data} &  &  &  &  &  \\
Physical integrity & 0.024 & 0.013 & 66.674 & 0.9564 & 17902 \\
Militias & -0.099 & 0.048 & 73.104 & 0.9490 & 17902 \\
Years since last mass killing & 0.006 & 0.002 & 88.208 & 0.9472 & 101583 \\
Previous riots & 0.078 & 0.041 & 65.412 & 0.9348 & 17902 \\
Ethnic diversity (ELF) & 0.095 & 0.062 & 48.615 & 0.9000 & 17902 \\
 &  &  &  &  &  \\
\textit{Cederman et al. data} &  &  &  &  &  \\
Territory aims & -0.051 & 0.026 & 74.288 & 0.9167 & 17902 \\
Militias & -0.050 & 0.035 & 52.240 & 0.9101 & 17902 \\ \hline
\end{tabular}
\caption{EBA -- Mass Killings during Civil Wars}
\label{tab:ucdp1}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-ucdp.pdf}
    \caption{EBA -- Mass Killings during Civil Wars (UCDP Data)}
    \label{fig:mk-ucdp}
\end{sidewaysfigure}
\clearpage

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-cow.pdf}
    \caption{EBA -- Mass Killings during Civil Wars (COW Data)}
    \label{fig:mk-cow}
\end{sidewaysfigure}
\clearpage

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-eth.pdf}
    \caption{EBA -- Mass Killings during ethnic civil wars (Cederman et al. Data)}
    \label{fig:mk-eth}
\end{sidewaysfigure}
\clearpage

\subsubsection{Alternative Number of Variables}

The models below are based on 50,000 random draws from the full set of all possible regression models. \citet[819]{salaimartin2004determinants} argue that random sampling produces unbiased estimates of the regression coefficients with low computational time. The models presented in section \ref{sec:results4}, however, include the full set of possible regressions.

The following table shows the results of an EBA with 3 variable combinations per model. The results are very similar to those reported above.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & 0.0082 & 0.0043 & 81.439 & 0.9504 & 40677 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.0121 & 0.0069 & 77.804 & 0.9609 & 5064 \\
UCDP civil war onset & 0.0523 & 0.0292 & 62.561 & 0.9574 & 3304 \\
Previous riots &0.0134 & 0.0084 & 65.936 & 0.9401 & 5064 \\
UCDP ongoing civil war & 0.0177 & 0.0094 & 72.367 & 0.9372 & 3304 \\
Polity IV squared & -0.0002 & 0.0001 & 66.035 & 0.9268 & 5064 \\ 
Ethnic diversity (ELF) & 0.0162 & 0.0110 & 70.794 & 0.9266 & 5064 \\\hline
\end{tabular}
\caption{EBA -- 3 Variables}
\label{tab:mk-3vars}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-3vars.pdf}
    \caption{EBA -- 3 Variables}
    \label{fig:mk-3vars}
\end{sidewaysfigure}
\clearpage

Table \ref{tab:mk-5vars} presents the results for models with up 5 variables in each regressions. In contrast with our main EBA model, the indicators of UCDP ongoing civil wars, ethnic diversity, and Polity IV square drop out of significance. Their individual CDFs(0) are about 0.88, just marginally below our specified threshold of 0.9.

\vspace{1cm}

\begin{table}[!htpb]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.010 & 0.006 & 70.806 & 0.9161 & 50000 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.014 & 0.010 & 68.496 & 0.9336 & 9532 \\
UCDP civil war onset & 0.053 & 0.035 & 44.784 & 0.9308 & 5100 \\
Previous riots & 0.015 & 0.012 & 47.988 & 0.9047 & 9569 \\\hline
\end{tabular}
\caption{EBA -- 5 Variables}
\label{tab:mk-5vars}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-5vars.pdf}
    \caption{EBA -- 5 Variables}
    \label{fig:mk-5vars}
\end{sidewaysfigure}
\clearpage

\subsubsection{Alternative Variance Inflation Factors}

In this subsection, we estimate EBA models with different values of Variance Inflation Factor (VIF), which is a measure of multicollinearity. There is no standard definition about what constitutes an acceptable VIF value, although researchers often use 10 as rule of thumb to indicate strong multicollinearity \citep[674]{o2007caution}. Our original model used a slightly more conservative value of 7 as a cutoff. Here, we test the same model with VIF $=$ 10 (less strict), 2.5 (more conservative), and a model without VIF restrictions. The results are essentially identical to those of the main model. In the model with no VIF restriction, however, ethnic fractionalisation fails to meet the threshold by a very small margin. The CDF(0) of that covariate is 0.897, very close to the required value of 0.9. 

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.0091 & 0.0052 & 76.354 & 0.9343 & 50000 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.0134 & 0.0084 & 73.540 & 0.9495 & 7929 \\
UCDP civil war onset & 0.0529 & 0.0322 & 52.141 & 0.9438 & 4553 \\
Previous riots & 0.0140 & 0.0100 & 56.433 & 0.9216 & 7772 \\
UCDP ongoing civil war & 0.0172 & 0.0113 & 66.013 & 0.9113 & 4587 \\
Ethnic diversity (ELF) & 0.0182 & 0.0136 & 56.872 & 0.9056 & 8076 \\
Polity IV squared & -0.0002 & 0.0001 & 60.791 & 0.9021 & 7835 \\ \hline
\end{tabular}
\caption{EBA -- VIF 10}
\label{tab:mk-high-vif}
\end{table}


\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-high-vif.pdf}
    \caption{EBA -- VIF 10}
    \label{fig:mk-high-vif}
\end{sidewaysfigure}
\clearpage

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.0090 & 0.0051 & 76.055 & 0.9343 & 49620 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.0132 & 0.0084 & 72.845 & 0.9490 & 7929 \\
UCDP civil war onset & 0.0529 & 0.0322 & 52.378 & 0.9438 & 4553 \\
Previous riots & 0.0141 & 0.0101 & 56.242 & 0.9199 & 7772 \\
UCDP ongoing civil war & 0.0174 & 0.0114 & 65.652 & 0.9103 & 4587 \\
Ethnic diversity (ELF) & 0.0184 & 0.0137 & 56.674 & 0.9054 & 8076 \\
Polity IV squared & -0.0002 & 0.0001 & 61.206 & 0.90267 & 7835 \\ \hline
\end{tabular}
\caption{EBA -- VIF 2.5}
\label{tab:low-vif}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-low-vif.pdf}
    \caption{EBA -- VIF 2.5}
    \label{fig:mk-low-vif}
\end{sidewaysfigure}
\clearpage

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.0091 & 0.0052 & 75.940 & 0.9343 & 50000 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
Post-Cold War years & -0.0133 & 0.0085 & 72.756 & 0.9469 & 7800 \\
UCDP civil war onset & 0.0531 & 0.0321 & 53.068 & 0.9452 & 4596 \\
Previous riots & 0.0140 & 0.0101 & 56.139 & 0.9200 & 7811 \\
UCDP ongoing civil war & 0.0170 & 0.0116 & 64.487 & 0.9057 & 4497 \\
Ethnic diversity (ELF) & 0.0184 & 0.0137 & 56.814 & 0.9056 & 7808 \\
Polity IV squared & -0.0002 & 0.0001 & 60.825 & 0.9009 & 7903 \\ \hline
\end{tabular}
\caption{EBA -- No VIF Restriction}
\label{tab:mk-no-vif}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-no-vif.pdf}
    \caption{EBA -- No VIF restriction}
    \label{fig:mk-no-vif}
\end{sidewaysfigure}
\clearpage

\subsubsection{Generalised Linear Models}

We reestimate the main EBA model with logit and probit models. Nevertheless, logistic and probit regressions may have issues of complete separation, that is, some covariates may perfectly separate zeros and ones in the outcome variable. In that case, the estimations fail to converge. We address this problem by adding a weak prior to the regression coefficients as suggested by \citet{gelman2008weakly}.\footnote{We thank Mark Bell for sharing \texttt{R} code to estimate penalised-likelihood models.} First, we scaled the non-binary variables to have a mean of 0 and a standard deviation of 0.5, then added a Cauchy distribution with centre 0 and scale 2.5. The probit regressions use a scale of $2.5 \times 1.6$, which is also recommended by the authors \citep{arm2017rpackage}. Ethnic diversity and ongoing civil wars come close to meeting our threshold values (0.88 and 0.84, respectively), and civil war onset (UCDP) has a higher percentage of significant coefficients and a high CDF(0) area than in the linear probability models.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & 0.434 & 0.223 & 75.570 & 0.9267 & 50000 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
UCDP civil war onset & 1.308 & 0.530 & 87.261 & 0.9742 & 4506 \\
Post-Cold War years & -0.911 & 0.428 & 70.456 & 0.9448 & 7890 \\
Previous riots & 0.744 & 0.38 & 66.778 & 0.9383 & 7805 \\
Polity IV squared & -0.015 & 0.008 & 68.038 & 0.9285 & 7975 \\ \hline
\end{tabular}
\caption{EBA -- Logistic Regression}
\label{tab:mk-logit}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-logit.pdf}
    \caption{EBA -- Logistic Regression}
    \label{fig:mk-logit}
\end{sidewaysfigure}
\clearpage

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{Base variables} &  &  &  &  &  \\
Log GDP per capita & -0.1924 & 0.1031 & 76.118 & 0.9258 & 50000 \\
 &  &  &  &  &  \\
\textit{Additional variables} &  &  &  &  &  \\
UCDP civil war onset & 0.6422 & 0.2582 & 89.225 & 0.9772 & 4501 \\
Previous riots & 0.3367 & 0.1743 & 71.813 & 0.9436 & 7851 \\
Post-Cold War years & -0.3709 & 0.1830 & 71.465 & 0.9404 & 7836 \\
Polity IV squared & -0.0061 & 0.0032 & 70.155 & 0.9315 & 7931 \\ \hline
\end{tabular}
\caption{EBA -- Probit Regression}
\label{tab:eba1}
\end{table}

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/mk-probit.pdf}
    \caption{EBA -- Probit Regression}
    \label{fig:mk-probit}
\end{sidewaysfigure}
\clearpage

\subsection{Random Forest Extensions}
\label{sec:mk-rfe}

\subsubsection{Alternative Random Seeds}

As noted in section \ref{sec:methods4}, we perform a grid search to optimise the hyperparameters of the random forest models. The grid search evaluates a wide range of parameter values at once, therefore it is generally unnecessary to run additional tests to assess the robustness of the results. Nevertheless, as random forests themselves are an approximation to a number of possible parameter combinations, changes in seed numbers may influence the output. Thus, we start the models with different random seed numbers to evaluate how sturdy are our original results.\footnote{The numbers were generated at \href{https://www.random.org/}{https://www.random.org/}.} The findings holds quite well: Although variable importance changes from one model to another, the most significant variables appear repeatedly in the estimations. The marginal plots also show that their effects on the outcome variable remains similar despite eventual nonlinearities. We show the six most significant predictors of mass killings and their respective partial dependence plots.

\begin{figure}[H]
    \centering
    \includegraphics{images/drf-mk2.pdf}
    \caption{Variable Importance -- Seed 44849999}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=9cm]{images/drfdpp2.pdf}
    \caption{Partial Plots -- Seed 44849999}
    \label{fig:my_label}
\end{figure}

\newpage

Second model -- seed 1502436: 

\begin{figure}[H]
    \centering
    \includegraphics{images/drf-mk3.pdf}
    \caption{Variable Importance -- Seed 1502436}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=9cm]{images/drfdpp3a.pdf}
    \caption{Partial Plots -- Seed 1502436}
    \label{fig:my_label}
\end{figure}

\newpage

\subsection{Genocides/Politicides}
\label{sec:mk-other-variable}

In this section, we evaluate the models presented above with a measure of genocide and politicide by \citet{harff2003no}. The results show important contrasts with the previous analyses. First, no variable appear as significant in the main extreme bounds analysis. That is, none of the 36 predictors reached the threshold of CDF(0) $> 0.9$. The variable that came closest to significance was a dummy indicator of coups d'état, which has a CDF(0) of 0.897 and, as expected, is positively correlated with the onset of genocides. The distibution of the covariates' coefficients are available in figure \ref{fig:uamk}.

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/uamk.pdf}
    \caption{EBA -- Genocides/Politicides}
    \label{fig:uamk}
\end{sidewaysfigure}
\clearpage

\subsubsection{Genocides/Politicides during Civil Wars}

Next, we evaluate what covariates are robust when considering only genocides and politicide that occur during civil conflicts. Post-Cold War years again appear as a significant variable and with a negative sign; excluded population also has a negative impact on the outcome variable in two analyses.

\vspace{1cm}

\begin{table}[H]
\centering
\begin{tabular}{lrrrrr}
\hline
\textbf{Variable} & \textbf{Avg. $\beta$} & \textbf{Avg. SE} & \textbf{$\%$ Sig.} & \textbf{CDF(0)} & \textbf{Models} \\ \hline
\textit{UCDP data} &  &  &  &  &  \\
Excluded population & -0.037 & 0.022 & 64.524 & 0.9176 & 8758 \\
 &  &  &  &  &  \\
\textit{COW data} &  &  &  &  &  \\
Excluded population & -0.057 & 0.031 & 65.703 & 0.9570 & 8820 \\
Discriminated population & -0.050 & 0.029 & 53.850 & 0.93.67 & 8767 \\
Post-Cold War years & -0.019 & 0.013 & 42.531 & 0.9203 & 8904 \\
 &  &  &  &  &  \\
\textit{Cederman et al. data} &  &  &  &  &  \\
Assassination dummy & -0.009 & 0.006 & 47.723 & 0.9232 & 8828 \\ \hline
\end{tabular}
\caption{EBA -- Genocides/Politicides}
\label{tab:uamk1}
\end{table}

\newpage
\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/uamk-ucdp.pdf}
    \caption{EBA -- Genocides and Politicides during Civil Wars (UCDP Data)}
    \label{fig:uamk-ucdp}
\end{sidewaysfigure}
\clearpage

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/uamk-cow.pdf}
    \caption{EBA -- Genocides and Politicides during Civil Wars (COW Data)}
    \label{fig:uamk-cow}
\end{sidewaysfigure}
\clearpage

\clearpage
\begin{sidewaysfigure}
    \centering
    \includegraphics[width=\textwidth]{images/uamk-eth.pdf}
    \caption{EBA -- Genocides and Politicides during Ethnic Civil Wars (Cederman et al. Data)}
    \label{fig:uamk-eth}
\end{sidewaysfigure}
\clearpage

\newpage
\subsection{Genocides/Politicides -- Random Forests}

Lastly, we present three models using the distributed random forest algorithm \citep{h2o2017}. The results are in line with those obtained with the mass killing variable by  \citet{ulfelder2008assessing}. Again, we see that CINC, the percentage of urban population, and variables concerning the military are some of the most important predictors of state-led violence. The results confirm the overall finding of the chapter: Poor countries are more likely to experience mass killings, and states with a stronger army see a significant upward shift in genocide risk.

\begin{figure}[H]
    \centering
    \includegraphics{images/drf-gp.pdf}
    \caption{Variable Importance -- Genocides/Politicides}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=9cm]{images/drfdpp4a.pdf}
    \caption{Partial Plots -- Genocides/Politicides}
    \label{fig:my_label}
\end{figure}

\newpage

The next graphs show the most important predictors of genocides that occur during civil wars and their respective partial dependence plots. 

\begin{figure}[H]
    \centering
    \includegraphics{images/drf-gp1.pdf}
    \caption{Variable Importance -- Genocides/Politicides (UCDP Data)}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=9cm]{images/drfdpp5a.pdf}
    \caption{Partial Plots -- Genocides/Politicides (UCDP Data)}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{images/drf-gp2.pdf}
    \caption{Variable Importance -- Genocides/Politicides (COW Data)}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=9cm]{images/drfdpp6a.pdf}
    \caption{Partial Plots -- Genocides/Politicides (COW Data)}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{images/drf-gp3.pdf}
    \caption{Variable Importance -- Genocides/Politicides (Cederman et al. Data)}
    \label{fig:my_label}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth, height=9cm]{images/drfdpp7a.pdf}
    \caption{Partial Plots -- Genocides/Politicides (Cederman et al. Data)}
    \label{fig:my_label}
\end{figure}

\newpage

\subsection{\texttt{R} Code}
\label{sec:mk-code}

The \texttt{R} code below reproduces the analyses presented in chapter \ref{chap:killings}.

\singlespacing
\small
\begin{verbatim}
######################
### Data Wrangling ###
######################

## Install and load required packages 
if (!require("tidyverse")) {
        install.packages("tidyverse")
}
if (!require("data.table")) {
        install.packages("data.table")
}
if (!require("ExtremeBounds")) {
        install.packages("ExtremeBounds")
}
if (!require("h2o")) {
        install.packages("h2o")
}
if (!require("sandwich")) {
        install.packages("sandwich")
}
if (!require("arm")) {
        install.packages("arm")
}
if (!require("stargazer")) {
        install.packages("stargazer")
}

## Load dataset
df <- haven::read_dta("data/base variables.dta") %>% setDT()

## Select and lag variables
sd.cols <- c("UCDPcivilwarstart", "UCDPcivilwarongoing", "COWcivilwarstart",
             "COWcivilwarongoing", "ethnowarstart", "ethnowarongoing",
             "assdummy", "demdummy", "elf", "lmtnest", "pop", "realgdp",
             "rgdppc", "polity2", "exclpop", "discpop", "polrqnew",
             "poltrqnew", "egiptpolrqnew", "egippolrqnew", "discrim",
             "elf2", "interstatewar", "milex", "milper", "percentpopurban",
             "postcoldwar", "coupdummy", "riotdummy", "territoryaims",
             "totaltrade", "tradedependence", "militias", "physint", "cinc",
             "totalbeaths", "change", "guerrilladummy", "sf", "regtrans")

df1 <- cbind(df, df[, shift(.SD, 1, give.names = TRUE),
                    by = ccode, .SDcols = sd.cols]) 

# Remove the second `ccode` variable
df1 <- as.data.frame(df1[, -c(70)])

# Add new variables
df1$logrgdppc_lag_1 <- log(df1$rgdppc_lag_1)
df1$polity2sq_lag_1 <- df1$polity2_lag_1^2

# UCDP civil war == 1
df.ucdp <- df1 %>% filter(UCDPcivilwarongoing == 1)
df.ucdp <- as.data.frame(df.ucdp[, c(1:7, 76:111)])
names(df.ucdp) <- sub("_.*","", names(df.ucdp)) 

# COW civil war == 1
df.cow <- df1 %>% filter(COWcivilwarongoing == 1)
df.cow <- as.data.frame(df.cow[, c(1:7, 76:111)])
names(df.cow) <- sub("_.*","", names(df.cow)) 

# Ethnic civil war == 1
df.eth <- df1 %>% filter(ethnowarongoing == 1)
df.eth <- as.data.frame(df.eth[, c(1:7, 76:111)])
names(df.eth) <- sub("_.*","", names(df.eth)) 

# Regular model
df2 <- as.data.frame(df1[, c(1:7, 70:111)])
names(df2) <- sub("_.*","", names(df2)) 


###############################
### Extreme Bounds Analyses ###
###############################

## Classifying a few variables as mutually exclusive.
## "Change" was removed because it was correlated at 0.99 with "regtrans". 
free.variables <- c("logrgdppc", "polity2", "mksyr")
civilwar.variables <- c("UCDPcivilwarongoing", "UCDPcivilwarstart",
                        "COWcivilwarongoing", "COWcivilwarstart",
                        "ethnowarongoing", "ethnowarstart")
doubtful.variables <- c("UCDPcivilwarongoing", "UCDPcivilwarstart",
                        "COWcivilwarongoing", "COWcivilwarstart",
                        "ethnowarongoing", "ethnowarstart", "assdummy",
                        "totaltrade", "tradedependence", "milper", "milex",
                        "pop", "totalbeaths", "guerrilladummy", "regtrans",
                        "riotdummy", "territoryaims", "militias",
                        "physint", "percentpopurban", "coupdummy",
                        "postcoldwar",  "lmtnest", "realgdp", "discrim",
                        "exclpop", "discpop", "elf",  "polrqnew",
                        "egippolrqnew", "poltrqnew", "egiptpolrqnew",
                        "polity2sq")

# Cluster-robust standard errors
se.clustered.robust <- function(model.object){
        model.fit <- vcovHC(model.object, type = "HC", cluster = "country")
        out <- sqrt(diag(model.fit))
        return(out)
}

# Main model
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df2, vif = 7, level = 0.9,
          se.fun = se.clustered.robust)

summary(m1)
hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "mksyr",
                       "UCDPcivilwarongoing",
                       "UCDPcivilwarstart", "COWcivilwarongoing",
                       "COWcivilwarstart", "ethnowarongoing", "ethnowarstart",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last mass killing",
              "UCDP ongoing", "UCDP onset", "COW ongoing", "COW onset", 
              "Ethnic ongoing", "Ethnic onset", "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Group/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")
          
# Mass killings during civil war
# UCDP civil conflicts == 1
doubtful.variables <- c("assdummy", "totaltrade", "tradedependence",
                        "milper", "milex", "pop", "totalbeaths",
                        "guerrilladummy", "regtrans", "riotdummy",
                        "territoryaims", "militias", "physint",
                        "percentpopurban", "coupdummy", "postcoldwar",
                        "lmtnest", "realgdp", "discrim", "exclpop",
                        "discpop", "elf",  "polrqnew", "egippolrqnew",
                        "poltrqnew", "egiptpolrqnew", "polity2sq")

m1 <- eba(y = "MKstart", free = free.variables,
          doubtful = doubtful.variables, k = 0:4,
          data = df.ucdp, vif = 7,
          level = 0.9, se.fun = se.clustered.robust)
          
summary(m1)
hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "mksyr",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last mass killing",
              "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Group/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")
     
# COW civil wars == 1
doubtful.variables <- c("assdummy", "totaltrade", "tradedependence",
                        "milper", "milex", "pop", "totalbeaths",
                        "guerrilladummy", "regtrans", "riotdummy",
                        "territoryaims", "militias", "physint",
                        "percentpopurban", "coupdummy", "postcoldwar",
                        "lmtnest", "realgdp", "discrim", "exclpop",
                        "discpop", "elf",  "polrqnew", "egippolrqnew",
                        "poltrqnew", "egiptpolrqnew", "polity2sq")

m1 <- eba(y = "MKstart", free = free.variables,
          doubtful = doubtful.variables, k = 0:4,
          data = df.cow, vif = 7,
          level = 0.9, se.fun = se.clustered.robust)
          
summary(m1)
hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "mksyr",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last mass killing",
              "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Group/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")
     
# Ethnic civil war == 1
doubtful.variables <- c("assdummy", "totaltrade", "tradedependence",
                        "milper", "milex", "pop", "totalbeaths",
                        "guerrilladummy", "regtrans", "riotdummy",
                        "territoryaims", "militias", "physint",
                        "percentpopurban", "coupdummy", "postcoldwar",
                        "lmtnest", "realgdp", "discrim", "exclpop", 
                        "discpop", "elf",  "polrqnew", "egippolrqnew",
                        "poltrqnew", "egiptpolrqnew", "polity2sq")

m1 <- eba(y = "MKstart", free = free.variables,
          doubtful = doubtful.variables, k = 0:4,
          data = df.eth, vif = 7,
          level = 0.9, se.fun = se.clustered.robust)
          
summary(m1)
hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "mksyr",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last mass killing",
              "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Group/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")

## Different values of k
## Code for the histogram not included as it is the same as that of the main model.

# 3 variables per model
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:3,
          data = df2, vif = 7, level = 0.9, draws = 50000,
          se.fun = se.clustered.robust)

# 5 variables per model
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:5,
          data = df2, vif = 7, draws = 50000,
          level = 0.9, se.fun = se.clustered.robust)
          
## Alternative VIFs

# VIF = 10
# Low VIF
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df2, vif = 10, level = 0.9, draws = 50000,
          se.fun = se.clustered.robust)

# VIF = 2.5
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df2, vif = 2.5, level = 0.9, draws = 50000,
          se.fun = se.clustered.robust)

# No VIF
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df2, level = 0.9, draws = 50000,
          se.fun = se.clustered.robust)

## Generalised linear models

# Logit
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df2, level = 0.9, vif = 7, draws = 50000,
          reg.fun = bayesglm, family = binomial(link = "logit"))
          
# Probit
m1 <- eba(y = "MKstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df2, level = 0.9, vif = 7, draws = 50000,
          reg.fun = bayesglm, family = binomial(link = "probit"))
          

##################################
### Distributed Random Forests ###
##################################

## Random Forests

## Prepare the data set
h2o.init(nthreads = -1, max_mem_size = "20g") # memory size

df2a <- as.h2o(df2)

df2a$MKstart <- as.factor(df2a$MKstart)  # encode the binary response as a factor
h2o.levels(df2a$MKstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility

train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "MKstart"
x <- setdiff(names(df2), c(y, "ccode", "year", "rgdppc",
                           "mksyr2", "mksyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf01",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

# Saving the most accurate model
rf.grid <- h2o.getGrid(grid_id = "gridrf01",
                       sort_by = "auc",
                       decreasing = TRUE)

rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

# Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf01_model_21")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Polity IV", 
                      "Military personnel",
                      "Ethnic polarisation", 
                      "% Urban pop.",
                      "Years mass killing",
                      "Log GDP per capita"),
        main = "")

logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p1 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Log GDP per capita") + ylab("Mean response")

mksyr <- h2o.partialPlot(object = a, data = train, cols = c("mksyr"))
p2 <- qplot(mksyr$mksyr, mksyr$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Years since mass killing") +  ylab("Mean response")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p3 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + ylim(0, 0.05) + xlab("% Urban") + ylab("Mean response")

egiptpolrqnew <- h2o.partialPlot(object = a, data = train, cols = c("egiptpolrqnew"))
p4 <- qplot(egiptpolrqnew$egiptpolrqnew, egiptpolrqnew$mean_response) + geom_line() +
        theme_classic() + ylim(0, 0.05) + xlab("Ethnic polarisation") + ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p5 <- qplot(milper$milper, milper$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Military personnel") + ylab("Mean response")

polity2 <- h2o.partialPlot(object = a, data = train, cols = c("polity2"))
p6 <- qplot(polity2$polity2, polity2$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Polity IV") + ylab("Mean response")
        
# Multiplot function: http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
        library(grid)
        
        # Make a list from the ... arguments and plotlist
        plots <- c(list(...), plotlist)
        
        numPlots = length(plots)
        
        # If layout is NULL, then use 'cols' to determine layout
        if (is.null(layout)) {
                # Make the panel
                # ncol: Number of columns of plots
                # nrow: Number of rows needed, calculated from # of cols
                layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                                 ncol = cols, nrow = ceiling(numPlots/cols))
        }
        
        if (numPlots==1) {
                print(plots[[1]])
                
        } else {
                # Set up the page
                grid.newpage()
                pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
                
                # Make each plot, in the correct location
                for (i in 1:numPlots) {
                        # Get the i,j matrix positions of the regions that contain this subplot
                        matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
                        
                        print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                                        layout.pos.col = matchidx$col))
                }
        }
}

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

## Different seeds

rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf01b",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 44849999)) 

# Saving the most accurate model
rf.grid <- h2o.getGrid(grid_id = "gridrf01b",
                       sort_by = "auc",
                       decreasing = TRUE)

rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

# Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf01b_model_8")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Population", 
                      "Military personnel",
                      "Trade dependence", 
                      "Log GDP per capita",
                      "% Urban pop.",
                      "Years mass killing"),
        main = "")

mksyr <- h2o.partialPlot(object = a, data = train, cols = c("mksyr"))
p1 <- qplot(mksyr$mksyr, mksyr$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Years since mass killing") +  ylab("Mean response")
        
percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p2 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + ylim(0, 0.05) + xlab("% Urban") + ylab("Mean response")

logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p3 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Log GDP per capita") + ylab("Mean response")

tradedependence <- h2o.partialPlot(object = a, data = train, cols = c("tradedependence"))
p4 <- qplot(tradedependence$tradedependence, tradedependence$mean_response) + geom_line() +
        theme_classic() + ylim(0, 0.05) + xlab("Trade dependence") + ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p5 <- qplot(milper$milper, milper$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Military personnel") + ylab("Mean response")

pop <- h2o.partialPlot(object = a, data = train, cols = c("pop"))
p6 <- qplot(pop$pop, pop$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Population") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)


rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf01c",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 1502436)) 

# Saving the most accurate model
rf.grid <- h2o.getGrid(grid_id = "gridrf01c",
                       sort_by = "auc",
                       decreasing = TRUE)

rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

# Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf01c_model_58")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Population", 
                      "Military personnel",
                      "Trade dependence", 
                      "Log GDP per capita",
                      "% Urban pop.",
                      "Years mass killing"),
        main = "")

mksyr <- h2o.partialPlot(object = a, data = train, cols = c("mksyr"))
p1 <- qplot(mksyr$mksyr, mksyr$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Years since mass killing") +  ylab("Mean response")
        
percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p2 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + ylim(0, 0.05) + xlab("% Urban") + ylab("Mean response")

logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p3 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Log GDP per capita") + ylab("Mean response")

tradedependence <- h2o.partialPlot(object = a, data = train, cols = c("tradedependence"))
p4 <- qplot(tradedependence$tradedependence, tradedependence$mean_response) + geom_line() +
        theme_classic() + ylim(0, 0.05) + xlab("Trade dependence") + ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p5 <- qplot(milper$milper, milper$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Military personnel") + ylab("Mean response")

pop <- h2o.partialPlot(object = a, data = train, cols = c("pop"))
p6 <- qplot(pop$pop, pop$mean_response) + geom_line() + theme_classic() + ylim(0, 0.05) +
        xlab("Population) + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

## Genocides in civil wars

## UCDP data
df.ucdpa <- as.h2o(df.ucdp)

df.ucdpa$MKstart <- as.factor(df.ucdpa$MKstart)  # encode the binary response as a factor
h2o.levels(df.ucdpa$MKstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.ucdpa, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility

train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "MKstart"
x <- setdiff(names(df.ucdp), c(y, "ccode", "year", "rgdppc",
                           "mksyr2", "mksyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf02",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf02",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

# Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf02_model_34")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Total battle deaths", 
                      "Log GDP per capita",
                       "Trade dependence",
                      "Military personnel",
                      "% Urban pop.",
                      "Years mass killing"),
        main = "")
        
mksyr <- h2o.partialPlot(object = a, data = train, cols = c("mksyr"))
p1 <- qplot(mksyr$mksyr, mksyr$mean_response) + geom_line() + theme_classic() + 
        ylim(0, 0.1) + xlab("Years since mass killing") +  ylab("Mean response")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p2 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        ylim(0, 0.1) + theme_classic() + xlab("% Urban") + ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p3 <- qplot(milper$milper, milper$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.25) + xlab("Military personnel") + ylab("Mean response")

tradedependence <- h2o.partialPlot(object = a, data = train, cols = c("tradedependence"))
p4 <- qplot(tradedependence$tradedependence, tradedependence$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.1) + xlab("Trade dependence") + ylab("Mean response")

logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p5 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.1) + xlab("Log GDP per capita") + ylab("Mean response")

totalbeaths <- h2o.partialPlot(object = a, data = train, cols = c("totalbeaths"))
p6 <- qplot(totalbeaths$totalbeaths, totalbeaths$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.35) + xlab("Total battle deaths") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

## COW data
df.cowa <- as.h2o(df.cow)

df.cowa$MKstart <- as.factor(df.cowa$MKstart)
h2o.levels(df.cowa$MKstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.cowa, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42) 

train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "MKstart"
x <- setdiff(names(df.ucdp), c(y, "ccode", "year", "rgdppc",
                               "mksyr2", "mksyr3", "sf", "country",
                               "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf03",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf03",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## Graphs
a <- h2o.loadModel("/root/Documents/mk/gridrf03_model_3")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 
par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Total battle deaths", 
                      "Excluded population",
                      "Yrs since mass killing",
                      "Log GDP per capita",
                      "Ethnic polarisation",
                      "Physical integrity"),
        main = "")

physint <- h2o.partialPlot(object = a, data = train, cols = c("physint"))
p1 <- qplot(physint$physint, physint$mean_response) + geom_line() + theme_classic() + 
        xlab("Physical integrity") +  ylab("Mean response")

egiptpolrqnew <- h2o.partialPlot(object = a, data = train, cols = c("egiptpolrqnew"))
p2 <- qplot(egiptpolrqnew$egiptpolrqnew, egiptpolrqnew$mean_response) + geom_line() +
        theme_classic() + xlab("Ethnic polarisation") + ylab("Mean response")

logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p3 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.1) + xlab("Log GDP per capita") + ylab("Mean response")

mksyr <- h2o.partialPlot(object = a, data = train, cols = c("mksyr"))
p4 <- qplot(mksyr$mksyr, mksyr$mean_response) + geom_line() + theme_classic() + 
        ylim(0, 0.1) + xlab("Years since mass killing") +  ylab("Mean response")

exclpop <- h2o.partialPlot(object = a, data = train, cols = c("exclpop"))
p5 <- qplot(exclpop$exclpop, exclpop$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.1) + xlab("Excluded population") + ylab("Mean response")

totalbeaths <- h2o.partialPlot(object = a, data = train, cols = c("totalbeaths"))
p6 <- qplot(totalbeaths$totalbeaths, totalbeaths$mean_response) + geom_line() + theme_classic() +
        ylim(0, 0.1) + xlab("Total battle deaths") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

## Ethnic war
df.etha <- as.h2o(df.eth)

df.etha$MKstart <- as.factor(df.etha$MKstart) 
h2o.levels(df.etha$MKstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.etha, 
                         ratios = c(0.7, 0.15), 
                         seed = 42) 

train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "MKstart"
x <- setdiff(names(df.eth), c(y, "ccode", "year", "rgdppc",
                               "mksyr2", "mksyr3", "sf", "country",
                               "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf04",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf04",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

# Graphs
a <- h2o.loadModel("/root/Documents/mk/gridrf04_model_14")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Military expenditure",
                      "Total trade", 
                      "% Urban",
                      "Trade dependence",
                      "Military personnel",
                      "CINC"),
        main = "")


cinc <- h2o.partialPlot(object = a, data = train, cols = c("cinc"))
p1 <- qplot(cinc$cinc, cinc$mean_response) + geom_line() + theme_classic() + 
        xlab("CINC") +  ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p2 <- qplot(milper$milper, milper$mean_response) + geom_line() +
        theme_classic() + xlab("Military personnel") + ylab("Mean response")

tradedependence <- h2o.partialPlot(object = a, data = train, cols = c("tradedependence"))
p3 <- qplot(tradedependence$tradedependence, tradedependence$mean_response) + geom_line() + theme_classic() +
        xlab("Trade dependence") + ylab("Mean response")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p4 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
       theme_classic() + xlab("% Urban") + ylab("Mean response")

totaltrade <- h2o.partialPlot(object = a, data = train, cols = c("totaltrade"))
p5 <- qplot(totaltrade$totaltrade, totaltrade$mean_response) + geom_line() +
        theme_classic() + xlab("Total trade") + ylab("Mean response")

milex <- h2o.partialPlot(object = a, data = train, cols = c("milex"))
p6 <- qplot(milex$milex, milex$mean_response) + geom_line() +
        theme_classic() + xlab("Military expenditure") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

####################################
### Genocide/Politicide Variable ###
####################################

## The code below replicates the same analyses presented above
## but using a measure of genocide/politicide coded by Harff (2003).

## Data wrangling
df3 <- haven::read_dta("data/uamkstart.dta") %>% setDT()

sd.cols <- c("UCDPcivilwarstart", "UCDPcivilwarongoing", "COWcivilwarstart",
             "COWcivilwarongoing", "ethnowarstart", "ethnowarongoing",
             "assdummy", "demdummy", "elf", "lmtnest", "pop", "realgdp",
             "rgdppc", "polity2", "exclpop", "discpop", "polrqnew",
             "poltrqnew", "egiptpolrqnew", "egippolrqnew", "discrim",
             "elf2", "interstatewar", "milex", "milper", "percentpopurban",
             "postcoldwar", "coupdummy", "riotdummy", "territoryaims",
             "totaltrade", "tradedependence", "militias", "physint", "cinc",
             "totalbeaths", "change", "guerrilladummy", "sf", "regtrans")

df4 <- cbind(df3, df3[, shift(.SD, 1, give.names = TRUE),
                      by = ccode, .SDcols = sd.cols]) 

# Remove the second `ccode` variable
df4 <- as.data.frame(df4[, -c(75)])

# Add new variables
df4$logrgdppc_lag_1 <- log(df4$rgdppc_lag_1)
df4$polity2sq_lag_1 <- df4$polity2_lag_1^2

# Renaming variables
df5 <- as.data.frame(df4[, c(1:4, 72:116)])
names(df5) <- sub("_.*","", names(df5)) 

#################################################
### Distributed Random Forests - Harff (2003) ###
#################################################

df5a <- as.h2o(df5)

df5a$uamkstart <- as.factor(df5a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df5a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df5a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df5), c(y, "ccode", "year", "rgdppc",
                           "uamkyr2", "uamkyr3", "sf", "country",
                           "elf2", "polity2sq")) 
# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, 
               grid_id = "gridrf05",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 
                                      
# Saving the most accurate model
rf.grid <- h2o.getGrid(grid_id = "gridrf05",
                       sort_by = "auc",
                       decreasing = TRUE)

rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf05_model_27")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Real GDP", 
                      "Military expenditure",
                      "Total trade", 
                      "Military personnel",
                      "CINC", 
                      "% Urban"),
        main = "")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p1 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + xlab("% Urban") + ylab("Mean response")
        
cinc <- h2o.partialPlot(object = a, data = train, cols = c("cinc"))
p2 <- qplot(cinc$cinc, cinc$mean_response) + geom_line() + theme_classic() + 
        xlab("CINC") +  ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p3 <- qplot(milper$milper, milper$mean_response) + geom_line() +
        theme_classic() + xlab("Military personnel") + ylab("Mean response")

totaltrade <- h2o.partialPlot(object = a, data = train, cols = c("totaltrade"))
p4 <- qplot(totaltrade$totaltrade, totaltrade$mean_response) + geom_line() + theme_classic() +
        xlab("Total trade") + ylab("Mean response")

milex <- h2o.partialPlot(object = a, data = train, cols = c("milex"))
p5 <- qplot(milex$milex, milex$mean_response) + geom_line() +
        theme_classic() + xlab("Military expenditure") + ylab("Mean response")
        
realgdp <- h2o.partialPlot(object = a, data = train, cols = c("realgdp"))
p6 <- qplot(realgdp$realgdp, realgdp$mean_response) + geom_line() +
        theme_classic() + xlab("Real GDP") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)


## UCDP == 1
df.ucdp2 <- df5 %>% filter(UCDPcivilwarongoing == 1)
df.ucdp2a <- as.h2o(df.ucdp2)

df.ucdp2a$uamkstart <- as.factor(df.ucdp2a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df.ucdp2a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.ucdp2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df.ucdp2), c(y, "ccode", "year", "rgdppc",
                           "uamkyr2", "uamkyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf06",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf06",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf06_model_43")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Excluded population",
                      "% Urban pop.", 
                      "Trade dependence",
                      "Log GDP per capita",
                      "Years since genocide", 
                      "Military personnel"),
        main = "")
        
milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p1 <- qplot(milper$milper, milper$mean_response) + geom_line() +
        theme_classic() + xlab("Military personnel") + ylab("Mean response")

uamkyr <- h2o.partialPlot(object = a, data = train, cols = c("uamkyr"))
p2 <- qplot(uamkyr$uamkyr, uamkyr$mean_response) + geom_line() + theme_classic() + 
        xlab("Years since genocide") +  ylab("Mean response")
        
logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p3 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() +
        xlab("Log GDP per capita") + ylab("Mean response")

tradedependence <- h2o.partialPlot(object = a, data = train, cols = c("tradedependence"))
p4 <- qplot(tradedependence$tradedependence, tradedependence$mean_response) + geom_line() +
        theme_classic() + xlab("Trade dependence") + ylab("Mean response")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p5 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + xlab("% Urban") + ylab("Mean response")
        
exclpop <- h2o.partialPlot(object = a, data = train, cols = c("exclpop"))
p6 <- qplot(exclpop$exclpop, exclpop$mean_response) + geom_line() +
        theme_classic() + xlab("Excluded population") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

## COW == 1
df.cow2 <- df5 %>% filter(COWcivilwarongoing == 1)

df.cow2a$uamkstart <- as.factor(df.cow2a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df.cow2a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.cow2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df.cow2), c(y, "ccode", "year", "rgdppc",
                               "uamkyr2", "uamkyr3", "sf", "country",
                               "elf2", "polity2sq")) 

## Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf07",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf07",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf07_model_27")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Military expenditure",
                      "% Urban pop.", 
                      "Total trade",
                      "Years since genocide", 
                      "Military personnel", 
                      "Trade dependence"),
        main = "")

uamkyr <- h2o.partialPlot(object = a, data = train, cols = c("uamkyr"))
p3 <- qplot(uamkyr$uamkyr, uamkyr$mean_response) + geom_line() + theme_classic() + 
        xlab("Years since genocide") +  ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p2 <- qplot(milper$milper, milper$mean_response) + geom_line() +
        theme_classic() + xlab("Military personnel") + ylab("Mean response")

totaltrade <- h2o.partialPlot(object = a, data = train, cols = c("totaltrade"))
p4 <- qplot(totaltrade$totaltrade, totaltrade$mean_response) + geom_line() + theme_classic() +
        xlab("Total trade") + ylab("Mean response")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p5 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + xlab("% Urban") + ylab("Mean response")

tradedependence <- h2o.partialPlot(object = a, data = train, cols = c("tradedependence"))
p1 <- qplot(tradedependence$tradedependence, tradedependence$mean_response) + geom_line() +
        theme_classic() + xlab("Trade dependence") + ylab("Mean response")

milex <- h2o.partialPlot(object = a, data = train, cols = c("milex"))
p6 <- qplot(milex$milex, milex$mean_response) + geom_line() +
        theme_classic() + xlab("Military expenditure") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)

## ETHONSET == 1
df.eth2 <- df5 %>% filter(ethnowarongoing == 1)

df.eth2a <- as.h2o(df.eth2)

df.eth2a$uamkstart <- as.factor(df.eth2a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df.eth2a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.eth2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df.eth2), c(y, "ccode", "year", "rgdppc",
                               "uamkyr2", "uamkyr3", "sf", "country",
                               "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf08",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 1000, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf08",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## Graphs
a <- h2o.loadModel("/home/sussa/Documents/GitHub/mk/gridrf08_model_55")
print(va <- a %>% h2o.varimp() %>% as.data.frame() %>% head(., 6)) 

par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(2,7.5,1,1))
barplot(va$scaled_importance[6:1],
        horiz = TRUE, las = 1, cex.names=0.9,
        names.arg = c("Total battle deaths", 
                      "Military personnel",
                      "Log GDP per capita", 
                      "CINC",
                      "% Urban",
                      "Military expenditure"),
        main = "")

cinc <- h2o.partialPlot(object = a, data = train, cols = c("cinc"))
p3 <- qplot(cinc$cinc, cinc$mean_response) + geom_line() + theme_classic() + 
        xlab("CINC") +  ylab("Mean response")

milper <- h2o.partialPlot(object = a, data = train, cols = c("milper"))
p5 <- qplot(milper$milper, milper$mean_response) + geom_line() +
        theme_classic() + xlab("Military personnel") + ylab("Mean response")

logrgdppc <- h2o.partialPlot(object = a, data = train, cols = c("logrgdppc"))
p4 <- qplot(logrgdppc$logrgdppc, logrgdppc$mean_response) + geom_line() + theme_classic() +
        xlab("Log GDP per capita") + ylab("Mean response")

percentpopurban <- h2o.partialPlot(object = a, data = train, cols = c("percentpopurban"))
p2 <- qplot(percentpopurban$percentpopurban, percentpopurban$mean_response) + geom_line() +
        theme_classic() + xlab("% Urban") + ylab("Mean response")

totalbeaths <- h2o.partialPlot(object = a, data = train, cols = c("totalbeaths"))
p6 <- qplot(totalbeaths$totalbeaths, totalbeaths$mean_response) + geom_line() +
        theme_classic() + xlab("Total battle deaths") + ylab("Mean response")

milex <- h2o.partialPlot(object = a, data = train, cols = c("milex"))
p1 <- qplot(milex$milex, milex$mean_response) + geom_line() +
        theme_classic() + xlab("Military expenditure") + ylab("Mean response")

multiplot(p1, p4, p2, p5, p3, p6, cols = 3)


##############################################
### Genocides and Politicides (Harff 2003) ###
##############################################

# Preparing the dataset
df3 <- haven::read_dta("data/uamkstart.dta") %>% setDT()
sd.cols <- c("UCDPcivilwarstart", "UCDPcivilwarongoing", "COWcivilwarstart",
             "COWcivilwarongoing", "ethnowarstart", "ethnowarongoing",
             "assdummy", "demdummy", "elf", "lmtnest", "pop", "realgdp",
             "rgdppc", "polity2", "exclpop", "discpop", "polrqnew",
             "poltrqnew", "egiptpolrqnew", "egippolrqnew", "discrim",
             "elf2", "interstatewar", "milex", "milper", "percentpopurban",
             "postcoldwar", "coupdummy", "riotdummy", "territoryaims",
             "totaltrade", "tradedependence", "militias", "physint", "cinc",
             "totalbeaths", "change", "guerrilladummy", "sf", "regtrans")

df4 <- cbind(df3, df3[, shift(.SD, 1, give.names = TRUE),
                    by = ccode, .SDcols = sd.cols]) 

# Remove the second `ccode` variable
df4 <- as.data.frame(df4[, -c(75)])

# Add new variables
df4$logrgdppc_lag_1 <- log(df4$rgdppc_lag_1)
df4$polity2sq_lag_1 <- df4$polity2_lag_1^2

# Renaming variables
df5 <- as.data.frame(df4[, c(1:4, 72:116)])
names(df5) <- sub("_.*","", names(df5)) 

## Extreme Bounds
free.variables <- c("logrgdppc", "polity2", "uamkyr")
civilwar.variables <- c("UCDPcivilwarongoing", "UCDPcivilwarstart",
                        "COWcivilwarongoing", "COWcivilwarstart",
                        "ethnowarongoing", "ethnowarstart")
doubtful.variables <- c("UCDPcivilwarongoing", "UCDPcivilwarstart",
                        "COWcivilwarongoing", "COWcivilwarstart",
                        "ethnowarongoing", "ethnowarstart", "assdummy",
                        "totaltrade", "tradedependence", "milper", "milex",
                        "pop", "totalbeaths", "guerrilladummy", "regtrans",
                        "riotdummy", "territoryaims", "militias",
                        "physint", "percentpopurban", "coupdummy",
                        "postcoldwar",  "lmtnest", "realgdp", "discrim",
                        "exclpop", "discpop", "elf",  "polrqnew",
                        "egippolrqnew", "poltrqnew", "egiptpolrqnew",
                        "polity2sq")
m1 <- eba(y = "uamkstart", free = free.variables,
          exclusive = list(civilwar.variables),
          doubtful = doubtful.variables, k = 0:4,
          data = df5, vif = 7, level = 0.9, 
          se.fun = se.clustered.robust)
          
hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "uamkyr",
                       "UCDPcivilwarongoing",
                       "UCDPcivilwarstart", "COWcivilwarongoing",
                       "COWcivilwarstart", "ethnowarongoing", "ethnowarstart",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last genocide",
              "UCDP ongoing", "UCDP onset", "COW ongoing", "COW onset", 
              "Ethnic ongoing", "Ethnic onset", "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Group/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")

### Ongoing Civil Wars

# UCDPcivilwarongoing == 1
df.ucdp2 <- df5 %>% filter(UCDPcivilwarongoing == 1)
doubtful.variables <- c("assdummy", "totaltrade", "tradedependence",
                        "milper", "milex", "pop", "totalbeaths",
                        "guerrilladummy", "regtrans", "riotdummy",
                        "territoryaims", "militias", "physint",
                        "percentpopurban", "coupdummy", "postcoldwar",
                        "lmtnest", "realgdp", "discrim", "exclpop",
                        "discpop", "elf",  "polrqnew", "egippolrqnew",
                        "poltrqnew", "egiptpolrqnew", "polity2sq")

m1 <- eba(y = "uamkstart", free = free.variables,
          doubtful = doubtful.variables, k = 0:4,
          data = df.ucdp2, vif = 7, draws = 50000,
          level = 0.9, se.fun = se.clustered.robust)
          
hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "uamkyr",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last genocide",
              "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Groups/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")
     
# COWcivilwarongoing == 1
df.cow2 <- df5 %>% filter(COWcivilwarongoing == 1)
doubtful.variables <- c("assdummy", "totaltrade", "tradedependence",
                        "milper", "milex", "pop", "totalbeaths",
                        "guerrilladummy", "regtrans", "riotdummy",
                        "territoryaims", "militias", "physint",
                        "percentpopurban", "coupdummy", "postcoldwar",
                        "lmtnest", "realgdp", "discrim", "exclpop",
                        "discpop", "elf",  "polrqnew", "egippolrqnew",
                        "poltrqnew", "egiptpolrqnew", "polity2sq")

m1 <- eba(y = "uamkstart", free = free.variables,
          doubtful = doubtful.variables, k = 0:4,
          data = df.cow2, vif = 7, draws = 50000,
          level = 0.9, se.fun = se.clustered.robust)

hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "uamkyr",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last genocide",
              "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Groups/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")
     
# ethnic civil war == 1
df.eth2 <- df5 %>% filter(ethnowarongoing == 1)
doubtful.variables <- c("assdummy", "totaltrade", "tradedependence",
                        "milper", "milex", "pop", "totalbeaths",
                        "guerrilladummy", "regtrans", "riotdummy",
                        "territoryaims", "militias", "physint",
                        "percentpopurban", "coupdummy", "postcoldwar",
                        "lmtnest", "realgdp", "discrim", "exclpop", 
                        "discpop", "elf",  "polrqnew", "egippolrqnew",
                        "poltrqnew", "egiptpolrqnew", "polity2sq")

m1 <- eba(y = "uamkstart", free = free.variables,
          doubtful = doubtful.variables, k = 0:4,
          data = df.eth2, vif = 7, draws = 50000,
          level = 0.9, se.fun = se.clustered.robust)

hist(m1, variables = c("logrgdppc", "polity2", "polity2sq", "uamkyr",
                       "assdummy", "totaltrade", "tradedependence", "milper",
                       "milex","pop", "totalbeaths", "guerrilladummy", "regtrans",
                       "riotdummy", "territoryaims", "militias", "physint",
                       "percentpopurban", "coupdummy", "postcoldwar",
                       "lmtnest", "realgdp", "discrim", "exclpop", "discpop",
                       "elf", "polrqnew", "egippolrqnew", "poltrqnew",
                       "egiptpolrqnew"),
     main = c("Log GDP capita", "Polity IV", "Polity IV^2", "Years last genocide",
              "Assassination", "Total trade", 
              "Trade dependence", "Military personnel", "Military expenditure", "Population", 
              "Total deaths", "Guerrilla", "Regime transition", "Riots",
              "Territory Aims", "Militias", "Physical integrity", "% Urban",
              "Coups", "Post-Cold War", "Mountainous terrain", "Real GDP",
              "Discrimination", "Excl pop", "Discrim pop", "ELF", "Groups/Eth relevant", 
              "Groups/Tot pop", "Inc groups/Eth relevant", "Inc groups/Tot pop"),
     density.col = "black", mu.col = "red3")
     
########################################################
### Genocide/Politicide -- Distributed Random Forest ###
########################################################

df5a <- as.h2o(df5)

df5a$uamkstart <- as.factor(df5a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df5a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df5a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df5), c(y, "ccode", "year", "rgdppc",
                           "uamkyr2", "uamkyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, 
               grid_id = "gridrf05",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 500, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

# Saving the most accurate model
rf.grid <- h2o.getGrid(grid_id = "gridrf05",
                       sort_by = "auc",
                       decreasing = TRUE)

rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## UCDP == 1
df.ucdp2a <- as.h2o(df.ucdp2)

df.ucdp2a$uamkstart <- as.factor(df.ucdp2a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df.ucdp2a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.ucdp2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df.ucdp2), c(y, "ccode", "year", "rgdppc",
                           "uamkyr2", "uamkyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf06",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 100, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf06",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## COW == 1
df.cow2a <- as.h2o(df.cow2)

df.cow2a$uamkstart <- as.factor(df.cow2a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df.cow2a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.cow2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df.cow2), c(y, "ccode", "year", "rgdppc",
                           "uamkyr2", "uamkyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf07",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 100, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf07",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)

## ETHONSET == 1
df.eth2a <- as.h2o(df.eth2)

df.eth2a$uamkstart <- as.factor(df.eth2a$uamkstart)  #encode the binary repsonse as a factor
h2o.levels(df.eth2a$uamkstart)

# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = df.eth2a, 
                         ratios = c(0.7, 0.15),  # 70%, 15%, 15%
                         seed = 42)  # reproducibility


train <- h2o.assign(splits[[1]], "train.hex")   
valid <- h2o.assign(splits[[2]], "valid.hex") 
test <- h2o.assign(splits[[3]], "test.hex")

y <- "uamkstart"
x <- setdiff(names(df.eth2), c(y, "ccode", "year", "rgdppc",
                           "uamkyr2", "uamkyr3", "sf", "country",
                           "elf2", "polity2sq")) 

# Running the model
rf <- h2o.grid("randomForest", x = x, y = y, training_frame = train, 
               validation_frame = valid, nfolds = 5, grid_id = "gridrf08",
               fold_assignment = "Stratified",
               hyper_params = list(ntrees = c(256, 512, 1024),
                                   max_depth = c(10, 20, 40),
                                   mtries = c(5, 6, 7),
                                   balance_classes = c(TRUE, FALSE),
                                   sample_rate = c(0.5, 0.632, 0.95),
                                   col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
                                   histogram_type = c("UniformAdaptive",
                                                      "Random",
                                                      "QuantilesGlobal",
                                                      "RoundRobin")),
               search_criteria = list(strategy = "RandomDiscrete", 
                                      max_models = 100, 
                                      stopping_metric = "auc", 
                                      stopping_tolerance = 0.01, 
                                      stopping_rounds = 5, 
                                      seed = 26227709)) 

rf.grid <- h2o.getGrid(grid_id = "gridrf08",
                       sort_by = "auc",
                       decreasing = TRUE)
rf2 <- h2o.getModel(rf.grid@model_ids[[1]])
h2o.saveModel(rf2, path = "/root/Documents/mk/")
summary(rf2)
varimp <- as.data.frame(h2o.varimp(rf2))
h2o.varimp_plot(rf2)
h2o.performance(rf2, newdata = test)
     
\end{verbatim}


\doublespacing
\normalsize